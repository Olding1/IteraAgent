"""Test script for v7.3-v7.6 new features.

This script tests:
- v7.3: uv integration and Trace visualization
- v7.4: PM inference mode
- v7.5: Tool metadata with schema
- v7.6: Pattern auto-selection
"""

import asyncio
import sys
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent))

# Load .env file
from dotenv import load_dotenv
load_dotenv()  # åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡

from src.core.env_manager import EnvManager
from src.core.pm import PM
from src.core.graph_designer import GraphDesigner
from src.core.simulator import Simulator
from src.llm import BuilderClient
from src.tools.registry import ToolRegistry, ToolMetadata
from src.utils import generate_trace_html, generate_trace_summary


def print_section(title: str):
    """Print section header."""
    print("\n" + "=" * 70)
    print(f"ğŸ§ª {title}")
    print("=" * 70)


async def test_uv_integration():
    """Test v7.3: uv integration."""
    print_section("v7.3 æµ‹è¯•: uv é›†æˆ")
    
    # Create a test agent directory
    test_dir = Path("agents/test_uv_agent")
    test_dir.mkdir(parents=True, exist_ok=True)
    
    # Create a simple requirements.txt
    (test_dir / "requirements.txt").write_text("pydantic>=2.0.0\n")
    
    # Test with uv enabled
    print("\nğŸ“¦ æµ‹è¯• uv é›†æˆ...")
    env_manager = EnvManager(test_dir, use_uv=True)
    
    result = env_manager.setup_environment()
    
    print(f"\nç»“æœ:")
    print(f"  âœ… æˆåŠŸ: {result.success}")
    print(f"  âš¡ ä½¿ç”¨ uv: {result.used_uv}")
    print(f"  ğŸ“Š æ€§èƒ½æŒ‡æ ‡: {result.metrics}")
    
    if result.metrics:
        print(f"\næ€§èƒ½æŠ¥å‘Š:")
        print(f"  - ä¸‹è½½æ—¶é—´: {result.metrics.get('download_time', 0):.2f}s")
        print(f"  - åˆ›å»ºç¯å¢ƒ: {result.metrics.get('venv_create_time', 0):.2f}s")
        print(f"  - å®‰è£…ä¾èµ–: {result.metrics.get('install_time', 0):.2f}s")
        print(f"  - æ€»è®¡: {result.metrics.get('total_time', 0):.2f}s")
    
    # Cleanup
    env_manager.cleanup()
    
    return result.success


async def test_trace_visualization():
    """Test v7.3: Trace visualization."""
    print_section("v7.3 æµ‹è¯•: ç»“æ„åŒ– Trace å¯è§†åŒ–")
    
    # Create a mock simulation result
    from src.schemas import SimulationResult, SimulationStep, SimulationIssue, SimulationStepType
    from datetime import datetime
    
    trace = SimulationResult(
        success=True,
        total_steps=3,
        steps=[
            SimulationStep(
                step_number=1,
                step_type=SimulationStepType.ENTER_NODE,
                node_id="agent",
                description="è¿›å…¥ agent èŠ‚ç‚¹,å‡†å¤‡å¤„ç†ç”¨æˆ·è¾“å…¥"
            ),
            SimulationStep(
                step_number=2,
                step_type=SimulationStepType.STATE_UPDATE,
                node_id="agent",
                description="æ›´æ–°çŠ¶æ€,æ·»åŠ ç”¨æˆ·æ¶ˆæ¯"
            ),
            SimulationStep(
                step_number=3,
                step_type=SimulationStepType.EXIT_NODE,
                node_id="agent",
                description="é€€å‡º agent èŠ‚ç‚¹,è¿”å›å“åº”"
            ),
        ],
        execution_trace="Step 1: Enter agent\nStep 2: Update state\nStep 3: Exit agent",
        simulated_at=datetime.now()
    )
    
    # Generate HTML
    output_path = Path("test_trace_report.html")
    html = generate_trace_html(trace, output_path)
    
    print(f"\nâœ… HTML æŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")
    print(f"   æ–‡ä»¶å¤§å°: {len(html)} å­—èŠ‚")
    
    # Generate summary
    summary = generate_trace_summary(trace)
    print(f"\nğŸ“ æ–‡æœ¬æ‘˜è¦:")
    print(summary)
    
    return True


async def test_pm_inference():
    """Test v7.4: PM inference mode."""
    print_section("v7.4 æµ‹è¯•: PM æ¨æ–­å¼åˆ†æ")
    
    # Initialize PM
    builder_client = BuilderClient.from_env()
    pm = PM(builder_client)
    
    # Test cases
    test_cases = [
        ("å¸®æˆ‘åšä¸ªèŠå¤©æœºå™¨äºº", "ç®€çŸ­è¾“å…¥"),
        ("åˆ›å»ºä¸€ä¸ªèƒ½å¤ŸæŸ¥è¯¢å…¬å¸æ–‡æ¡£å¹¶å›ç­”é—®é¢˜çš„ RAG Agent,éœ€è¦æ”¯æŒ PDF å’Œ Word æ–‡æ¡£", "è¯¦ç»†è¾“å…¥"),
    ]
    
    for user_input, case_name in test_cases:
        print(f"\nğŸ§ª æµ‹è¯•ç”¨ä¾‹: {case_name}")
        print(f"   è¾“å…¥: {user_input}")
        
        # Analyze with inference
        project_meta = await pm.analyze_with_inference(user_input)
        
        print(f"\n   ç»“æœ:")
        print(f"   - Agent åç§°: {project_meta.agent_name}")
        print(f"   - ç½®ä¿¡åº¦: {project_meta.confidence:.0%}")
        print(f"   - çŠ¶æ€: {project_meta.status}")
        print(f"   - å¤æ‚åº¦: {project_meta.complexity_score}/10")
        
        if project_meta.missing_info:
            print(f"   - ç¼ºå¤±ä¿¡æ¯: {', '.join(project_meta.missing_info)}")
        
        if project_meta.clarification_questions:
            print(f"   - æ¾„æ¸…é—®é¢˜:")
            for i, q in enumerate(project_meta.clarification_questions, 1):
                print(f"     {i}. {q}")
    
    return True


async def test_tool_metadata():
    """Test v7.5: Tool metadata with schema."""
    print_section("v7.5 æµ‹è¯•: å·¥å…·å…ƒæ•°æ® Schema æ”¯æŒ")
    
    # Create a tool metadata with schema
    metadata = ToolMetadata(
        name="test_search",
        description="æµ‹è¯•æœç´¢å·¥å…·",
        category="search",
        tags=["search", "web"],
        requires_api_key=True,
        openapi_schema={
            "type": "object",
            "properties": {
                "query": {"type": "string", "description": "æœç´¢æŸ¥è¯¢"},
                "max_results": {"type": "integer", "default": 5}
            },
            "required": ["query"]
        },
        examples=[
            {"query": "Agent Zero æ˜¯ä»€ä¹ˆ", "max_results": 3},
            {"query": "LangGraph æ•™ç¨‹"}
        ]
    )
    
    print(f"\nâœ… å·¥å…·å…ƒæ•°æ®åˆ›å»ºæˆåŠŸ:")
    print(f"   - åç§°: {metadata.name}")
    print(f"   - åˆ†ç±»: {metadata.category}")
    print(f"   - æ ‡ç­¾: {', '.join(metadata.tags)}")
    print(f"   - Schema: {'âœ“ å·²å®šä¹‰' if metadata.openapi_schema else 'âœ— æœªå®šä¹‰'}")
    print(f"   - ç¤ºä¾‹æ•°é‡: {len(metadata.examples)}")
    
    if metadata.openapi_schema:
        print(f"\n   Schema è¯¦æƒ…:")
        print(f"   - å‚æ•°: {list(metadata.openapi_schema.get('properties', {}).keys())}")
        print(f"   - å¿…éœ€: {metadata.openapi_schema.get('required', [])}")
    
    return True


async def test_pattern_selection():
    """Test v7.6: Pattern auto-selection."""
    print_section("v7.6 æµ‹è¯•: æ¶æ„è‡ªåŠ¨æ˜ å°„")
    
    # Initialize components
    builder_client = BuilderClient.from_env()
    designer = GraphDesigner(builder_client)
    
    # Test cases
    from src.schemas import ProjectMeta, TaskType, ExecutionStep
    
    test_cases = [
        (
            ProjectMeta(
                agent_name="SimpleBot",
                description="ç®€å•é—®ç­”",
                user_intent_summary="ç®€å•èŠå¤©",
                complexity_score=2
            ),
            "ç®€å•ä»»åŠ¡"
        ),
        (
            ProjectMeta(
                agent_name="CodeReviewer",
                description="ä»£ç å®¡æŸ¥å¹¶æä¾›æ”¹è¿›å»ºè®®",
                user_intent_summary="è¿­ä»£æ”¹è¿›ä»£ç ",
                complexity_score=5
            ),
            "è¿­ä»£æ”¹è¿›ä»»åŠ¡"
        ),
        (
            ProjectMeta(
                agent_name="ComplexAgent",
                description="å¤æ‚å¤šæ­¥éª¤ä»»åŠ¡",
                user_intent_summary="å¤šæ­¥éª¤æ‰§è¡Œ",
                complexity_score=8,
                execution_plan=[
                    ExecutionStep(step=1, role="Planner", goal="è§„åˆ’"),
                    ExecutionStep(step=2, role="Executor", goal="æ‰§è¡Œ"),
                    ExecutionStep(step=3, role="Reviewer", goal="å®¡æŸ¥"),
                    ExecutionStep(step=4, role="Finalizer", goal="å®Œæˆ"),
                ]
            ),
            "å¤æ‚å¤šæ­¥éª¤ä»»åŠ¡"
        ),
    ]
    
    for project_meta, case_name in test_cases:
        print(f"\nğŸ§ª æµ‹è¯•ç”¨ä¾‹: {case_name}")
        print(f"   å¤æ‚åº¦: {project_meta.complexity_score}/10")
        
        # Select pattern
        pattern = await designer.select_pattern(project_meta)
        
        print(f"\n   âœ… è‡ªåŠ¨é€‰æ‹© Pattern:")
        pattern_type_str = pattern.pattern_type.value if hasattr(pattern.pattern_type, 'value') else str(pattern.pattern_type)
        print(f"   - ç±»å‹: {pattern_type_str}")
        print(f"   - æè¿°: {pattern.description}")
        print(f"   - æœ€å¤§è¿­ä»£: {pattern.max_iterations}")
    
    return True


async def main():
    """Run all tests."""
    print("\n" + "=" * 70)
    print("ğŸš€ Agent Zero v7.3-v7.6 åŠŸèƒ½æµ‹è¯•")
    print("=" * 70)
    
    results = {}
    
    # v7.3 Tests
    try:
        results['uv_integration'] = await test_uv_integration()
    except Exception as e:
        print(f"\nâŒ uv é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        results['uv_integration'] = False
    
    try:
        results['trace_visualization'] = await test_trace_visualization()
    except Exception as e:
        print(f"\nâŒ Trace å¯è§†åŒ–æµ‹è¯•å¤±è´¥: {e}")
        results['trace_visualization'] = False
    
    # v7.4 Tests
    try:
        results['pm_inference'] = await test_pm_inference()
    except Exception as e:
        print(f"\nâŒ PM æ¨æ–­æµ‹è¯•å¤±è´¥: {e}")
        results['pm_inference'] = False
    
    # v7.5 Tests
    try:
        results['tool_metadata'] = await test_tool_metadata()
    except Exception as e:
        print(f"\nâŒ å·¥å…·å…ƒæ•°æ®æµ‹è¯•å¤±è´¥: {e}")
        results['tool_metadata'] = False
    
    # v7.6 Tests
    try:
        results['pattern_selection'] = await test_pattern_selection()
    except Exception as e:
        print(f"\nâŒ Pattern é€‰æ‹©æµ‹è¯•å¤±è´¥: {e}")
        results['pattern_selection'] = False
    
    # Summary
    print("\n" + "=" * 70)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“")
    print("=" * 70)
    
    for test_name, success in results.items():
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        print(f"  {test_name}: {status}")
    
    total = len(results)
    passed = sum(1 for s in results.values() if s)
    
    print(f"\næ€»è®¡: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
    else:
        print(f"\nâš ï¸  {total - passed} ä¸ªæµ‹è¯•å¤±è´¥")


if __name__ == "__main__":
    asyncio.run(main())
