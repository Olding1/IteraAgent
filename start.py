"""Startup script for Agent Zero system."""

import asyncio
import sys
import argparse
from pathlib import Path
import os
from dotenv import load_dotenv
from datetime import datetime

# Add src to path
sys.path.insert(0, str(Path(__file__).parent))

from src.llm import (
    BuilderAPIConfig,
    RuntimeAPIConfig,
    check_all_apis,
    HealthStatus,
)
from src.utils.debug_logger import set_debug_mode
from src.utils.i18n import t, set_language, get_language


def select_language(args) -> str:
    """Select language at startup."""
    if args.lang:
        return args.lang
    
    print("=" * 50)
    print("Select Language / é€‰æ‹©è¯­è¨€")
    print("=" * 50)
    print("1. ä¸­æ–‡ (Chinese)")
    print("2. English")
    choice = input("\nPlease select / è¯·é€‰æ‹© (1/2): ").strip()
    return 'zh' if choice == '1' else 'en'


def print_banner():
    """Print Agent Zero banner."""
    print("=" * 70)
    print(t('banner'))
    print(f"   {t('banner_subtitle')}")
    print("=" * 70)
    print()


async def check_system_health():
    """Check system health before starting."""
    print(t('health_check'))
    print("-" * 70)
    
    # Load environment variables
    load_dotenv()
    
    # Check Builder API
    builder_config = BuilderAPIConfig(
        provider=os.getenv("BUILDER_PROVIDER", "openai"),
        model=os.getenv("BUILDER_MODEL", "gpt-4o"),
        api_key=os.getenv("BUILDER_API_KEY", ""),
        base_url=os.getenv("BUILDER_BASE_URL"),
        timeout=int(os.getenv("BUILDER_TIMEOUT", "60")),
        max_retries=int(os.getenv("BUILDER_MAX_RETRIES", "3")),
        temperature=float(os.getenv("BUILDER_TEMPERATURE", "0.7")),
    )
    
    # Check Runtime API
    runtime_config = RuntimeAPIConfig(
        provider=os.getenv("RUNTIME_PROVIDER", "openai"),
        model=os.getenv("RUNTIME_MODEL", "gpt-3.5-turbo"),
        api_key=os.getenv("RUNTIME_API_KEY"),
        base_url=os.getenv("RUNTIME_BASE_URL"),
        timeout=int(os.getenv("RUNTIME_TIMEOUT", "30")),
        temperature=float(os.getenv("RUNTIME_TEMPERATURE", "0.7")),
    )
    
    print(f"\n{t('checking_builder_api')}")
    print(f"   {t('provider')}: {builder_config.provider}")
    print(f"   {t('model')}: {builder_config.model}")
    print(f"   {t('api_key')}: {t('api_key_configured') if builder_config.api_key else t('api_key_missing')}")
    
    print(f"\n{t('checking_runtime_api')}")
    print(f"   {t('provider')}: {runtime_config.provider}")
    print(f"   {t('model')}: {runtime_config.model}")
    print(f"   {t('api_key')}: {t('api_key_configured') if runtime_config.api_key else t('api_key_missing')}")
    
    # Perform health checks
    print(f"\n{t('testing_connectivity')}")
    try:
        builder_result, runtime_result = await check_all_apis(
            builder_config, runtime_config
        )
        
        print(f"\n   Builder API: {_get_status_emoji(builder_result.status)} {builder_result.status.value.upper()}")
        print(f"   {builder_result.message}")
        if builder_result.response_time_ms:
            print(f"   {t('response_time')}: {builder_result.response_time_ms}ms")
        
        print(f"\n   Runtime API: {_get_status_emoji(runtime_result.status)} {runtime_result.status.value.upper()}")
        print(f"   {runtime_result.message}")
        if runtime_result.response_time_ms:
            print(f"   {t('response_time')}: {runtime_result.response_time_ms}ms")
        
        # Check if both are healthy
        both_healthy = (
            builder_result.status == HealthStatus.HEALTHY
            and runtime_result.status == HealthStatus.HEALTHY
        )
        
        print("\n" + "-" * 70)
        if both_healthy:
            print(t('all_systems_ok'))
        else:
            print(t('partial_systems_down'))
            print(f"\n{t('check_suggestions')}")
            print(t('check_env_file'))
            print(t('check_network'))
            print(t('check_api_status'))
        
        return both_healthy
        
    except Exception as e:
        print(f"\n{t('health_check_failed')}: {e}")
        return False


def _get_status_emoji(status: HealthStatus) -> str:
    """Get emoji for health status."""
    if status == HealthStatus.HEALTHY:
        return "âœ…"
    elif status == HealthStatus.UNHEALTHY:
        return "âŒ"
    else:
        return "â“"


def show_menu():
    """Show main menu."""
    print("\n" + "=" * 70)
    print(t('main_menu'))
    print("=" * 70)
    print(f"\n1. {t('menu_create')}")
    print(f"2. {t('menu_view')}")
    print(f"3. {t('menu_retest')}")
    print(f"4. {t('menu_config')}")
    print(f"5. {t('menu_tests')}")
    print(f"6. {t('menu_docs')}")
    print(f"7. {t('menu_export')}")
    print(f"8. {t('menu_webui')}")
    print(f"9. {t('menu_exit')}")
    print()


async def main():
    """Main entry point."""
    print_banner()
    
    # Check if .env exists
    if not Path(".env").exists():
        print("âš ï¸  æœªæ‰¾åˆ° .env æ–‡ä»¶!")
        print("\nè¯·ä»æ¨¡æ¿åˆ›å»º .env æ–‡ä»¶:")
        print("   cp .env.template .env")
        print("\nç„¶åç¼–è¾‘ .env å¹¶æ·»åŠ æ‚¨çš„ API Keysã€‚")
        print()
        return
    
    # Run health check
    is_healthy = await check_system_health()
    
    if not is_healthy:
        print(f"\n{t('partial_systems_down')}")
        print("   " + ("éƒ¨åˆ†åŠŸèƒ½å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œã€‚" if get_language() == 'zh' else "Some features may not work properly."))
        response = input(f"\n{t('continue_anyway')}: ")
        if response.lower() != 'y':
            print(f"\n{t('exiting')}")
            return
    
    # Show menu
    while True:
        show_menu()
        choice = input(f"{t('select_option')}: ").strip()
        
        # ğŸ”„ è¾…åŠ©å‡½æ•°: é‡æ–°åŠ è½½æ ¸å¿ƒæ¨¡å—
        def reload_core_modules():
            """é‡æ–°åŠ è½½æ ¸å¿ƒæ¨¡å—,é¿å… Python æ¨¡å—ç¼“å­˜é—®é¢˜"""
            import importlib
            import sys
            
            modules = [
                'src.core.runner',
                'src.core.compiler',
                'src.core.graph_designer',
                'src.core.graph_optimizer',
                'src.core.rag_optimizer',
                'src.core.tool_optimizer',
                'src.core.compiler_optimizer',
            ]
            
            for module_name in modules:
                if module_name in sys.modules:
                    try:
                        importlib.reload(sys.modules[module_name])
                    except Exception as e:
                        # é™é»˜å¤±è´¥,ä¸å½±å“ä¸»æµç¨‹
                        pass
        
        if choice == "1":
            try:
                from src.cli.factory_cli import run_interactive_factory
                await run_interactive_factory()
                
                # ğŸ”„ é‡æ–°åŠ è½½æ ¸å¿ƒæ¨¡å—
                reload_core_modules()
                print("âœ… æ ¸å¿ƒæ¨¡å—å·²æ›´æ–°")
                
            except ImportError as e:
                print(f"âŒ æ— æ³•åŠ è½½ Agent å·¥å‚: {e}")
            except Exception as e:
                print(f"âŒ è¿è¡Œå·¥å‚æ—¶å‡ºé”™: {e}")
        elif choice == "2":
            print("\nğŸ“¦ å·²ç”Ÿæˆçš„ Agent")
            agents_dir = Path("agents")
            if agents_dir.exists():
                agents = [d for d in agents_dir.iterdir() if d.is_dir() and not d.name.startswith('.')]
                if agents:
                    for i, agent in enumerate(agents, 1):
                        print(f"   {i}. {agent.name}")
                    
                    print("\nè¯·è¾“å…¥åºå·é€‰æ‹©è¦è¿è¡Œçš„ Agent (æˆ–è¾“å…¥ 0 è¿”å›):")
                    try:
                        idx = int(input("> "))
                        if idx > 0 and idx <= len(agents):
                            target_agent = agents[idx-1].resolve()
                            print(f"\nğŸš€ æ­£åœ¨å¯åŠ¨ {target_agent.name}...")
                            
                            # Decide action
                            print("è¯·é€‰æ‹©æ“ä½œ:")
                            print("1. ğŸ’¬ äº¤äº’å¼è¿è¡Œ (python agent.py)")
                            print("2. ğŸ§ª è¿è¡Œæµ‹è¯• (pytest)")
                            action = input("> ").strip()
                            
                            if action == "1":
                                # Run python agent.py
                                install_script = target_agent / ("install.bat" if os.name == "nt" else "install.sh")
                                agent_script = target_agent / "agent.py"
                                
                                # Check venv
                                if os.name == "nt":
                                    venv_python = target_agent / "venv" / "Scripts" / "python.exe"
                                else:
                                    venv_python = target_agent / "venv" / "bin" / "python"
                                    
                                if not venv_python.exists():
                                    print("âš ï¸  æœªæ£€æµ‹åˆ°è™šæ‹Ÿç¯å¢ƒï¼Œå°è¯•ä½¿ç”¨ç³»ç»Ÿ Python...")
                                    venv_python = "python"
                                
                                import subprocess
                                # Use subprocess to run agent.py in new window or current console
                                # For simplicity, current console but blocking
                                try:
                                    print("-" * 50)
                                    print(f"Executing with: {venv_python}")
                                    subprocess.run([str(venv_python), str(agent_script)], cwd=str(target_agent))
                                except Exception as e:
                                    print(f"æ‰§è¡Œå‡ºé”™: {e}")
                                    
                            elif action == "2":
                                # Run pytest
                                if os.name == "nt":
                                    venv_python = target_agent / "venv" / "Scripts" / "python.exe"
                                else:
                                    venv_python = target_agent / "venv" / "bin" / "python"
                                    
                                if not venv_python.exists():
                                    venv_python = "python"
                                    
                                test_file = target_agent / "tests" / "test_deepeval.py"
                                if not test_file.exists():
                                    print("âš ï¸  æœªæ‰¾åˆ° DeepEval æµ‹è¯•æ–‡ä»¶ï¼Œå°è¯•è¿è¡Œæ‰€æœ‰æµ‹è¯•...")
                                    test_args = []
                                else:
                                    test_args = [str(test_file)]
                                
                                import subprocess
                                try:
                                    cmd = [str(venv_python), "-m", "pytest"] + test_args + ["-v", "-s"]
                                    print(f"Executing: {' '.join(cmd)}")
                                    subprocess.run(cmd, cwd=str(target_agent))
                                except Exception as e:
                                    print(f"æµ‹è¯•å‡ºé”™: {e}")
                        elif idx == 0:
                            pass
                        else:
                            print("æ— æ•ˆåºå·")
                    except ValueError:
                        print("æ— æ•ˆè¾“å…¥")
                else:
                    print("   (ç©º) å°šæœªç”Ÿæˆä»»ä½• Agent")
            else:
                print("   (ç©º) agents ç›®å½•ä¸å­˜åœ¨")
        elif choice == "3":
            print("\nğŸ”„ é‡æ–°æµ‹è¯•ç°æœ‰ Agent (è¿­ä»£ä¼˜åŒ–)")
            print("=" * 50)
            
            agents_dir = Path("agents")
            if agents_dir.exists():
                agents = [d for d in agents_dir.iterdir() if d.is_dir() and not d.name.startswith('.')]
                
                if agents:
                    print("\nå¯ç”¨çš„ Agent:")
                    for i, agent in enumerate(agents, 1):
                        print(f"   {i}. {agent.name}")
                    
                    try:
                        idx = int(input("\nè¯·é€‰æ‹© Agent ç¼–å· (0=å–æ¶ˆ): ").strip())
                        if 1 <= idx <= len(agents):
                            target_agent = agents[idx - 1]
                            
                            # Load graph.json and metadata
                            graph_file = target_agent / "graph.json"
                            if not graph_file.exists():
                                print(f"âŒ æœªæ‰¾åˆ° graph.json: {graph_file}")
                                continue
                            
                            print(f"\nğŸ“‚ Agent: {target_agent.name}")
                            print(f"ğŸ“ è·¯å¾„: {target_agent}")
                            
                            # ğŸ”„ é‡æ–°åŠ è½½æ ¸å¿ƒæ¨¡å— (åœ¨å¯¼å…¥ä¹‹å‰!)
                            reload_core_modules()
                            
                            # Import necessary modules (åœ¨ reload ä¹‹åå¯¼å…¥!)
                            from src.core.agent_factory import AgentFactory
                            from src.core.runner import Runner
                            from src.core.judge import Judge
                            from src.core.report_manager import ReportManager
                            from src.cli.cli_callback import CLICallback
                            from src.schemas.graph_structure import GraphStructure
                            from src.schemas.rag_config import RAGConfig
                            from src.schemas.tools_config import ToolsConfig
                            from src.schemas.project_meta import ProjectMeta
                            from src.config.factory_config import AgentFactoryConfig
                            from src.llm.builder_client import BuilderClient
                            from src.core.graph_designer import GraphDesigner
                            from src.core.simulator import Simulator
                            from src.core.compiler import Compiler
                            from src.core.tool_selector import ToolSelector
                            import json
                            
                            # Load graph
                            with open(graph_file, 'r', encoding='utf-8') as f:
                                graph_data = json.load(f)
                            graph = GraphStructure.model_validate(graph_data)
                            
                            # Load RAG config if exists
                            rag_config = None
                            rag_file = target_agent / "rag_config.json"
                            if rag_file.exists():
                                with open(rag_file, 'r', encoding='utf-8') as f:
                                    rag_data = json.load(f)
                                rag_config = RAGConfig.model_validate(rag_data)
                            
                            # Load Tools config if exists
                            tools_config = None
                            tools_file = target_agent / "tools_config.json"
                            if tools_file.exists():
                                with open(tools_file, 'r', encoding='utf-8') as f:
                                    tools_data = json.load(f)
                                tools_config = ToolsConfig.model_validate(tools_data)
                            
                            # Create minimal metadata
                            pattern_data = graph_data.get('pattern', {})
                            if isinstance(pattern_data, dict):
                                pattern_type = pattern_data.get('pattern_type', 'sequential')
                            else:
                                pattern_type = str(pattern_data)
                            
                            task_type_map = {
                                'sequential': 'rag',
                                'router': 'rag',
                                'reflection': 'analysis',
                                'agent_supervisor': 'custom'
                            }
                            task_type = task_type_map.get(pattern_type, 'rag')
                            
                            meta = ProjectMeta(
                                agent_name=target_agent.name,
                                description=f"Retest of {target_agent.name}",
                                task_type=task_type,
                                has_rag=any('rag' in node.id.lower() for node in graph.nodes),
                                has_tools=False,
                                file_paths=[],
                                user_intent_summary=f"é‡æ–°æµ‹è¯• {target_agent.name}"
                            )
                            
                            # Initialize components
                            runner = Runner(target_agent)
                            judge = Judge()
                            report_manager = ReportManager(target_agent)
                            callback = CLICallback()
                            
                            # Initialize components for optimization
                            builder_client = BuilderClient.from_env()
                            designer = GraphDesigner(builder_client)
                            simulator = Simulator(builder_client)
                            compiler = Compiler(Path("src/templates"))
                            tool_selector = ToolSelector(builder_client)
                            
                            # Load history to determine next iteration
                            history = report_manager.load_history()
                            start_iteration = len(history.iterations)
                            
                            print(f"\nğŸ” å½“å‰è¿­ä»£å†å²: {len(history.iterations)} æ¬¡")
                            print(f"ğŸ“Š ä¸‹ä¸€æ¬¡è¿­ä»£: {start_iteration}")
                            
                            if history.iterations:
                                latest = history.get_latest_iteration()
                                print(f"ğŸ“ˆ æœ€æ–°é€šè¿‡ç‡: {latest.pass_rate:.1%}")
                            
                            # ğŸ†• Ask user if they want to skip testing
                            print("\né€‰æ‹©æ¨¡å¼:")
                            print("  1. è¿è¡Œæµ‹è¯• (çº¦6åˆ†é’Ÿ)")
                            print("  2. è·³è¿‡æµ‹è¯•,ä½¿ç”¨ä¸Šæ¬¡ç»“æœç›´æ¥ä¼˜åŒ– (å¿«é€Ÿ)")
                            mode_choice = input("è¯·é€‰æ‹© (1/2): ").strip()
                            
                            skip_testing = (mode_choice == "2")
                            
                            if skip_testing and not history.iterations:
                                print("âš ï¸  æ²¡æœ‰å†å²æµ‹è¯•ç»“æœ,å¿…é¡»å…ˆè¿è¡Œæµ‹è¯•")
                                skip_testing = False
                            
                            print("\né€‰æ‹©è¿­ä»£æ¨¡å¼:")
                            print("  y.    æ‰‹åŠ¨ç¡®è®¤ (æ¯æ¬¡è¿­ä»£è¯¢é—®)")
                            print("  auto. è‡ªåŠ¨è¿ç»­ (è‡ªåŠ¨è¿è¡Œ4æ¬¡, æ»¡åˆ†å³åœ)")
                            confirm = input("\nè¯·é€‰æ‹© (y/auto): ").strip().lower()
                            
                            auto_mode = (confirm == 'auto')
                            if confirm not in ['y', 'auto']:
                                print("å·²å–æ¶ˆ")
                                continue
                            
                            # ğŸ†• Automatic Iteration Loop
                            max_iterations = 4 if auto_mode else 5
                            
                            for iteration in range(start_iteration, start_iteration + max_iterations):
                                print("\n" + "=" * 70)
                                print(f"ğŸš€ å¼€å§‹è¿­ä»£ {iteration} ({'è‡ªåŠ¨æ¨¡å¼' if auto_mode else 'æ‰‹åŠ¨æ¨¡å¼'})")
                                print("=" * 70)
                                
                                try:
                                    # 1. Run tests or reuse previous results
                                    if skip_testing and iteration == start_iteration and history.iterations:
                                        # Reuse last iteration's report
                                        callback.on_log("   â­ï¸  è·³è¿‡æµ‹è¯•,ä½¿ç”¨ä¸Šæ¬¡ç»“æœ...")
                                        iteration_report = history.get_latest_iteration()
                                        # Update iteration ID
                                        iteration_report.iteration_id = iteration
                                        iteration_report.timestamp = datetime.now()
                                        
                                        # Create dummy test_results for compatibility
                                        from src.schemas.execution_result import ExecutionStatus, ExecutionResult, TestResult
                                        test_results = ExecutionResult(
                                            overall_status=ExecutionStatus.FAILED if iteration_report.failed_tests > 0 else ExecutionStatus.PASS,
                                            test_results=[
                                                TestResult(
                                                    test_id=tc.test_id,
                                                    status=ExecutionStatus.FAIL if tc.status.upper() in ["FAIL", "FAILED"] else ExecutionStatus.PASS,
                                                    actual_output=tc.actual_output,
                                                    error_message=tc.error_message,
                                                    duration_ms=int(tc.duration_seconds * 1000) if hasattr(tc, 'duration_seconds') else 0
                                                )
                                                for tc in iteration_report.test_cases
                                            ]
                                        )
                                    else:
                                        # Run tests normally
                                        callback.on_log("   â„¹ï¸  æ‰§è¡Œæµ‹è¯•...")
                                        test_results = runner.run_deepeval_tests(timeout=1200)
                                        
                                        # 2. Create report
                                        from src.schemas.test_report import TestCaseReport, IterationReport
                                        from src.schemas.execution_result import ExecutionStatus
                                        
                                        test_cases = []
                                        for test in test_results.test_results:
                                            test_cases.append(TestCaseReport(
                                                test_id=test.test_id,
                                                test_name=test.test_id,
                                                status=test.status.value.upper() if hasattr(test.status, 'value') else str(test.status).upper(),
                                                actual_output=test.actual_output or "",
                                                expected_output="",
                                                error_message=test.error_message,
                                                metrics={},
                                                duration_seconds=test.duration_ms / 1000.0 if test.duration_ms else 0.0
                                            ))
                                        
                                        total_tests = len(test_results.test_results)
                                        passed_tests = sum(1 for t in test_results.test_results if t.status.value in ['pass', 'success'])
                                        failed_tests = total_tests - passed_tests
                                        pass_rate = passed_tests / total_tests if total_tests > 0 else 0.0
                                        
                                        iteration_report = IterationReport(
                                            iteration_id=iteration,
                                            timestamp=datetime.now(),
                                            agent_name=meta.agent_name,
                                            total_tests=total_tests,
                                            passed_tests=passed_tests,
                                            failed_tests=failed_tests,
                                            skipped_tests=0,
                                            pass_rate=pass_rate,
                                            test_cases=test_cases,
                                            graph_snapshot=graph.model_dump(),
                                            rag_config_snapshot=rag_config.model_dump() if rag_config else None,
                                            tools_config_snapshot=tools_config.model_dump() if tools_config else None
                                        )
                                    
                                    # 3. Save initial report
                                    report_manager.save_iteration_report(iteration_report)
                                    
                                    # 4. Analyze with Judge
                                    judge_result = None
                                    analysis = None
                                    
                                    if test_results.overall_status != ExecutionStatus.SKIPPED:
                                        judge_result = judge.analyze_result(test_results)
                                        iteration_report.fix_target = judge_result.fix_target.value if judge_result.fix_target else None
                                        
                                        # 5. ğŸ†• LLM æ™ºèƒ½åˆ†æ
                                        if judge_result.error_type != "none":
                                            callback.on_log("   ğŸ¤– LLM æ™ºèƒ½åˆ†æä¸­...")
                                            
                                            from src.core.test_analyzer import TestAnalyzer
                                            test_analyzer = TestAnalyzer(builder_client)
                                            
                                            current_config = {
                                                "graph": graph.model_dump(),
                                                "rag": rag_config.model_dump() if rag_config else None,
                                                "tools": tools_config.model_dump() if tools_config else None
                                            }
                                            
                                            try:
                                                analysis = await test_analyzer.analyze_test_report(
                                                    iteration_report,
                                                    current_config
                                                )
                                                
                                                # Enhanced feedback
                                                enhanced_feedback = (
                                                    f"{judge_result.feedback}\n\n"
                                                    f"ğŸ¤– AI åˆ†æ:\n"
                                                    f"  ä¸»è¦é—®é¢˜: {analysis.primary_issue}\n"
                                                    f"  æ ¹æœ¬åŸå› : {analysis.root_cause}\n"
                                                    f"  é¢„è®¡æˆåŠŸç‡: {analysis.estimated_success_rate:.1%}\n"
                                                )
                                                
                                                if analysis.fix_strategy:
                                                    enhanced_feedback += "\nğŸ’¡ ä¿®å¤ç­–ç•¥:\n"
                                                    for i, step in enumerate(analysis.fix_strategy[:3], 1):
                                                        enhanced_feedback += (
                                                            f"  {i}. [{step.priority.upper()}] {step.action}\n"
                                                            f"     ç›®æ ‡: {step.target}\n"
                                                        )
                                                
                                                iteration_report.judge_feedback = enhanced_feedback
                                                
                                                # ğŸ” Debug: æ˜¾ç¤ºä¿®å¤ç­–ç•¥è¯¦æƒ…
                                                callback.on_log(f"\nğŸ” [DEBUG] ä¿®å¤ç­–ç•¥è¯¦æƒ…:")
                                                callback.on_log(f"  ç­–ç•¥æ€»æ•°: {len(analysis.fix_strategy)}")
                                                for i, step in enumerate(analysis.fix_strategy, 1):
                                                    callback.on_log(f"  ç­–ç•¥ {i}: target={step.target}, priority={step.priority}")
                                                    callback.on_log(f"         action={step.action[:80]}...")
                                            except Exception as e:
                                                callback.on_log(f"   âš ï¸ LLM åˆ†æå¤±è´¥: {str(e)}")
                                                iteration_report.judge_feedback = judge_result.feedback
                                        else:
                                            iteration_report.judge_feedback = judge_result.feedback if judge_result else ""
                                        
                                        # Update and save report
                                        report_manager.save_iteration_report(iteration_report)
                                    
                                    # 6. Display summary
                                    summary = report_manager.generate_summary(iteration)
                                    print(summary)
                                    
                                    # 7. Check pass rate threshold (BREAK ON 100%)
                                    if iteration_report.pass_rate >= 1.0:
                                        callback.on_log("âœ… æµ‹è¯•é€šè¿‡ç‡è¾¾æ ‡ (100%), åœæ­¢è¿­ä»£")
                                        break
                                    
                                    # 8. ğŸ†• Apply fix strategies
                                    if analysis and analysis.fix_strategy:
                                        callback.on_log("ğŸ”§ å¼€å§‹æ‰§è¡Œä¿®å¤ç­–ç•¥...")
                                        
                                        for fix_step in analysis.fix_strategy[:3]:
                                            # ğŸ” Debug: æ˜¾ç¤ºå½“å‰æ­¥éª¤è¯¦æƒ…
                                            callback.on_log(f"\n  ğŸ“ æ‰§è¡Œæ­¥éª¤ {fix_step.step}: {fix_step.action[:60]}...")
                                            callback.on_log(f"     [DEBUG] target={fix_step.target}, priority={fix_step.priority}")
                                            
                                            try:
                                                if fix_step.target == "rag_builder" and rag_config:
                                                    callback.on_log(f"     [DEBUG] è¿›å…¥ RAGOptimizer åˆ†æ”¯")
                                                    from src.core.rag_optimizer import RAGOptimizer
                                                    rag_optimizer = RAGOptimizer(builder_client)
                                                    
                                                    new_rag_config = await rag_optimizer.optimize_config(
                                                        rag_config,
                                                        analysis,
                                                        iteration_report
                                                    )
                                                    
                                                    callback.on_log(
                                                        f"    âœ… RAG ä¼˜åŒ–: k_retrieval {rag_config.k_retrieval} â†’ {new_rag_config.k_retrieval}"
                                                    )
                                                    
                                                    rag_config = new_rag_config
                                                    
                                                    # ğŸ’¾ ä¿å­˜é…ç½®åˆ°æ–‡ä»¶
                                                    import json
                                                    rag_config_file = target_agent / "rag_config.json"
                                                    with open(rag_config_file, 'w', encoding='utf-8') as f:
                                                        json.dump(rag_config.model_dump(), f, indent=2, ensure_ascii=False)
                                                    callback.on_log(f"    ğŸ’¾ å·²ä¿å­˜é…ç½®åˆ° {rag_config_file.name}")
                                                    
                                                    compiler.compile(meta, graph, rag_config, tools_config, target_agent)
                                                
                                                elif fix_step.target == "rag_builder" and not rag_config:
                                                    callback.on_log(f"     [DEBUG] è·³è¿‡ RAGOptimizer: rag_config ä¸å­˜åœ¨")
                                                
                                                elif fix_step.target == "tool_selector" and tools_config:
                                                    callback.on_log(f"     [DEBUG] è¿›å…¥ ToolOptimizer åˆ†æ”¯")
                                                    from src.core.tool_optimizer import ToolOptimizer
                                                    tool_optimizer = ToolOptimizer(builder_client, tool_selector)
                                                    
                                                    new_tools_config = await tool_optimizer.optimize_tools(
                                                        tools_config,
                                                        analysis,
                                                        meta
                                                    )
                                                    
                                                    callback.on_log(
                                                        f"    âœ… Tools ä¼˜åŒ–: {tools_config.enabled_tools} â†’ {new_tools_config.enabled_tools}"
                                                    )
                                                    
                                                    tools_config = new_tools_config
                                                
                                                elif fix_step.target == "tool_selector" and not tools_config:
                                                    callback.on_log(f"     [DEBUG] è·³è¿‡ ToolOptimizer: tools_config ä¸å­˜åœ¨")
                                                    compiler.compile(meta, graph, rag_config, tools_config, target_agent)
                                                
                                                elif fix_step.target == "graph_designer":
                                                    callback.on_log(f"     [DEBUG] è¿›å…¥ GraphOptimizer åˆ†æ”¯")
                                                    from src.core.graph_optimizer import GraphOptimizer
                                                    graph_optimizer = GraphOptimizer(designer, simulator)
                                                    
                                                    new_graph, sim_result = await graph_optimizer.optimize_graph(
                                                        graph,
                                                        analysis,
                                                        meta
                                                    )
                                                    
                                                    sim_status = "âœ… é€šè¿‡" if not sim_result.has_errors() else "âš ï¸ ä»æœ‰é—®é¢˜"
                                                    callback.on_log(f"    âœ… Graph ä¼˜åŒ–å®Œæˆ, ä»¿çœŸç»“æœ: {sim_status}")
                                                    
                                                    graph = new_graph
                                                    compiler.compile(meta, graph, rag_config, tools_config, target_agent)
                                                
                                                elif fix_step.target == "compiler":
                                                    callback.on_log(f"     [DEBUG] è¿›å…¥ CompilerOptimizer åˆ†æ”¯")
                                                    from src.core.compiler_optimizer import CompilerOptimizer
                                                    compiler_optimizer = CompilerOptimizer(compiler)
                                                    
                                                    error_msg = test_results.stderr or ""
                                                    success = await compiler_optimizer.optimize_dependencies(
                                                        target_agent,
                                                        analysis,
                                                        error_msg
                                                    )
                                                    
                                                    if success:
                                                        callback.on_log(f"    âœ… Compiler ä¼˜åŒ–: å·²æ›´æ–°ä¾èµ–é¡¹")
                                            
                                                else:
                                                    callback.on_log(f"     [DEBUG] æœªåŒ¹é…ä»»ä½•ä¼˜åŒ–å™¨åˆ†æ”¯")
                                                    callback.on_log(f"     [DEBUG] target='{fix_step.target}', rag_config={rag_config is not None}, tools_config={tools_config is not None}")
                                            
                                            except Exception as e:
                                                callback.on_log(f"    âš ï¸ ä¿®å¤æ­¥éª¤å¤±è´¥: {str(e)}")
                                                import traceback
                                                callback.on_log(f"    [DEBUG] å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()[:200]}")
                                    
                                    # 9. Iteration Control
                                    if iteration < start_iteration + max_iterations - 1:
                                        if auto_mode:
                                            callback.on_log(f"\nğŸ¤– [Auto] 3ç§’åå¼€å§‹ä¸‹ä¸€æ¬¡è¿­ä»£...")
                                            import time
                                            time.sleep(3)
                                        else:
                                            confirm = input("\nç»§ç»­ä¸‹ä¸€æ¬¡è¿­ä»£? (y/n): ").strip().lower()
                                            if confirm != 'y':
                                                callback.on_log("ç”¨æˆ·é€‰æ‹©åœæ­¢è¿­ä»£")
                                                break
                                
                                except Exception as e:
                                    print(f"\nâŒ è¿­ä»£ {iteration} å¤±è´¥: {e}")
                                    import traceback
                                    traceback.print_exc()
                                    break
                                    # 1. Run tests or reuse previous results
                                    if skip_testing and iteration == start_iteration and history.iterations:
                                        # Reuse last iteration's report
                                        callback.on_log("   â­ï¸  è·³è¿‡æµ‹è¯•,ä½¿ç”¨ä¸Šæ¬¡ç»“æœ...")
                                        iteration_report = history.get_latest_iteration()
                                        # Update iteration ID
                                        iteration_report.iteration_id = iteration
                                        iteration_report.timestamp = datetime.now()
                                        
                                        # Create dummy test_results for compatibility
                                        from src.schemas.execution_result import ExecutionStatus, ExecutionResult, TestResult
                                        test_results = ExecutionResult(
                                            overall_status=ExecutionStatus.FAILED if iteration_report.failed_tests > 0 else ExecutionStatus.PASS,
                                            test_results=[
                                                TestResult(
                                                    test_id=tc.test_id,
                                                    status=ExecutionStatus.FAIL if tc.status.upper() in ["FAIL", "FAILED"] else ExecutionStatus.PASS,
                                                    actual_output=tc.actual_output,
                                                    error_message=tc.error_message,
                                                    duration_ms=int(tc.duration_seconds * 1000) if hasattr(tc, 'duration_seconds') else 0
                                                )
                                                for tc in iteration_report.test_cases
                                            ]
                                        )
                                    else:
                                        # Run tests normally
                                        callback.on_log("   â„¹ï¸  æ‰§è¡Œæµ‹è¯•...")
                                        test_results = runner.run_deepeval_tests(timeout=600)
                                        
                                        # 2. Create report
                                        from src.schemas.test_report import TestCaseReport, IterationReport
                                        from src.schemas.execution_result import ExecutionStatus
                                        
                                        test_cases = []
                                        for test in test_results.test_results:
                                            test_cases.append(TestCaseReport(
                                                test_id=test.test_id,
                                                test_name=test.test_id,
                                                status=test.status.value.upper() if hasattr(test.status, 'value') else str(test.status).upper(),
                                                actual_output=test.actual_output or "",
                                                expected_output="",
                                                error_message=test.error_message,
                                                metrics={},
                                                duration_seconds=test.duration_ms / 1000.0 if test.duration_ms else 0.0
                                            ))
                                        
                                        total_tests = len(test_results.test_results)
                                        passed_tests = sum(1 for t in test_results.test_results if t.status.value in ['pass', 'success'])
                                        failed_tests = total_tests - passed_tests
                                        pass_rate = passed_tests / total_tests if total_tests > 0 else 0.0
                                        
                                        iteration_report = IterationReport(
                                            iteration_id=iteration,
                                            timestamp=datetime.now(),
                                            agent_name=meta.agent_name,
                                            total_tests=total_tests,
                                            passed_tests=passed_tests,
                                            failed_tests=failed_tests,
                                            skipped_tests=0,
                                            pass_rate=pass_rate,
                                            test_cases=test_cases,
                                            graph_snapshot=graph.model_dump(),
                                            rag_config_snapshot=rag_config.model_dump() if rag_config else None,
                                            tools_config_snapshot=tools_config.model_dump() if tools_config else None
                                        )
                                    
                                    # 3. Save initial report
                                    report_manager.save_iteration_report(iteration_report)
                                    
                                    # 4. Analyze with Judge
                                    judge_result = None
                                    analysis = None
                                    
                                    if test_results.overall_status != ExecutionStatus.SKIPPED:
                                        judge_result = judge.analyze_result(test_results)
                                        iteration_report.fix_target = judge_result.fix_target.value if judge_result.fix_target else None
                                        
                                        # 5. ğŸ†• LLM æ™ºèƒ½åˆ†æ
                                        if judge_result.error_type != "none":
                                            callback.on_log("   ğŸ¤– LLM æ™ºèƒ½åˆ†æä¸­...")
                                            
                                            from src.core.test_analyzer import TestAnalyzer
                                            test_analyzer = TestAnalyzer(builder_client)
                                            
                                            current_config = {
                                                "graph": graph.model_dump(),
                                                "rag": rag_config.model_dump() if rag_config else None,
                                                "tools": tools_config.model_dump() if tools_config else None
                                            }
                                            
                                            try:
                                                analysis = await test_analyzer.analyze_test_report(
                                                    iteration_report,
                                                    current_config
                                                )
                                                
                                                # Enhanced feedback
                                                enhanced_feedback = (
                                                    f"{judge_result.feedback}\n\n"
                                                    f"ğŸ¤– AI åˆ†æ:\n"
                                                    f"  ä¸»è¦é—®é¢˜: {analysis.primary_issue}\n"
                                                    f"  æ ¹æœ¬åŸå› : {analysis.root_cause}\n"
                                                    f"  é¢„è®¡æˆåŠŸç‡: {analysis.estimated_success_rate:.1%}\n"
                                                )
                                                
                                                if analysis.fix_strategy:
                                                    enhanced_feedback += "\nğŸ’¡ ä¿®å¤ç­–ç•¥:\n"
                                                    for i, step in enumerate(analysis.fix_strategy[:3], 1):
                                                        enhanced_feedback += (
                                                            f"  {i}. [{step.priority.upper()}] {step.action}\n"
                                                            f"     ç›®æ ‡: {step.target}\n"
                                                        )
                                                
                                                iteration_report.judge_feedback = enhanced_feedback
                                                
                                                # ğŸ” Debug: æ˜¾ç¤ºä¿®å¤ç­–ç•¥è¯¦æƒ…
                                                callback.on_log(f"\nğŸ” [DEBUG] ä¿®å¤ç­–ç•¥è¯¦æƒ…:")
                                                callback.on_log(f"  ç­–ç•¥æ€»æ•°: {len(analysis.fix_strategy)}")
                                                for i, step in enumerate(analysis.fix_strategy, 1):
                                                    callback.on_log(f"  ç­–ç•¥ {i}: target={step.target}, priority={step.priority}")
                                                    callback.on_log(f"         action={step.action[:80]}...")
                                            except Exception as e:
                                                callback.on_log(f"   âš ï¸ LLM åˆ†æå¤±è´¥: {str(e)}")
                                                iteration_report.judge_feedback = judge_result.feedback
                                        else:
                                            iteration_report.judge_feedback = judge_result.feedback if judge_result else ""
                                        
                                        # Update and save report
                                        report_manager.save_iteration_report(iteration_report)
                                    
                                    # 6. Display summary
                                    summary = report_manager.generate_summary(iteration)
                                    print(summary)
                                    
                                    # 7. Check pass rate threshold
                                    if iteration_report.pass_rate >= 0.9:
                                        callback.on_log("âœ… æµ‹è¯•é€šè¿‡ç‡è¾¾æ ‡ (â‰¥90%), åœæ­¢è¿­ä»£")
                                        break
                                    
                                    # 8. ğŸ†• Apply fix strategies
                                    if analysis and analysis.fix_strategy:
                                        callback.on_log("ğŸ”§ å¼€å§‹æ‰§è¡Œä¿®å¤ç­–ç•¥...")
                                        
                                        for fix_step in analysis.fix_strategy[:3]:
                                            # ğŸ” Debug: æ˜¾ç¤ºå½“å‰æ­¥éª¤è¯¦æƒ…
                                            callback.on_log(f"\n  ğŸ“ æ‰§è¡Œæ­¥éª¤ {fix_step.step}: {fix_step.action[:60]}...")
                                            callback.on_log(f"     [DEBUG] target={fix_step.target}, priority={fix_step.priority}")
                                            
                                            try:
                                                if fix_step.target == "rag_builder" and rag_config:
                                                    callback.on_log(f"     [DEBUG] è¿›å…¥ RAGOptimizer åˆ†æ”¯")
                                                    from src.core.rag_optimizer import RAGOptimizer
                                                    rag_optimizer = RAGOptimizer(builder_client)
                                                    
                                                    new_rag_config = await rag_optimizer.optimize_config(
                                                        rag_config,
                                                        analysis,
                                                        iteration_report
                                                    )
                                                    
                                                    callback.on_log(
                                                        f"    âœ… RAG ä¼˜åŒ–: k_retrieval {rag_config.k_retrieval} â†’ {new_rag_config.k_retrieval}"
                                                    )
                                                    
                                                    rag_config = new_rag_config
                                                    
                                                    # ğŸ’¾ ä¿å­˜é…ç½®åˆ°æ–‡ä»¶
                                                    import json
                                                    rag_config_file = target_agent / "rag_config.json"
                                                    with open(rag_config_file, 'w', encoding='utf-8') as f:
                                                        json.dump(rag_config.model_dump(), f, indent=2, ensure_ascii=False)
                                                    callback.on_log(f"    ğŸ’¾ å·²ä¿å­˜é…ç½®åˆ° {rag_config_file.name}")
                                                    
                                                    compiler.compile(meta, graph, rag_config, tools_config, target_agent)
                                                
                                                elif fix_step.target == "rag_builder" and not rag_config:
                                                    callback.on_log(f"     [DEBUG] è·³è¿‡ RAGOptimizer: rag_config ä¸å­˜åœ¨")
                                                
                                                elif fix_step.target == "tool_selector" and tools_config:
                                                    callback.on_log(f"     [DEBUG] è¿›å…¥ ToolOptimizer åˆ†æ”¯")
                                                    from src.core.tool_optimizer import ToolOptimizer
                                                    tool_optimizer = ToolOptimizer(builder_client, tool_selector)
                                                    
                                                    new_tools_config = await tool_optimizer.optimize_tools(
                                                        tools_config,
                                                        analysis,
                                                        meta
                                                    )
                                                    
                                                    callback.on_log(
                                                        f"    âœ… Tools ä¼˜åŒ–: {tools_config.enabled_tools} â†’ {new_tools_config.enabled_tools}"
                                                    )
                                                    
                                                    tools_config = new_tools_config
                                                
                                                elif fix_step.target == "tool_selector" and not tools_config:
                                                    callback.on_log(f"     [DEBUG] è·³è¿‡ ToolOptimizer: tools_config ä¸å­˜åœ¨")
                                                    compiler.compile(meta, graph, rag_config, tools_config, target_agent)
                                                
                                                elif fix_step.target == "graph_designer":
                                                    callback.on_log(f"     [DEBUG] è¿›å…¥ GraphOptimizer åˆ†æ”¯")
                                                    from src.core.graph_optimizer import GraphOptimizer
                                                    graph_optimizer = GraphOptimizer(designer, simulator)
                                                    
                                                    new_graph, sim_result = await graph_optimizer.optimize_graph(
                                                        graph,
                                                        analysis,
                                                        meta
                                                    )
                                                    
                                                    sim_status = "âœ… é€šè¿‡" if not sim_result.has_errors() else "âš ï¸ ä»æœ‰é—®é¢˜"
                                                    callback.on_log(f"    âœ… Graph ä¼˜åŒ–å®Œæˆ, ä»¿çœŸç»“æœ: {sim_status}")
                                                    
                                                    graph = new_graph
                                                    compiler.compile(meta, graph, rag_config, tools_config, target_agent)
                                                
                                                elif fix_step.target == "compiler":
                                                    callback.on_log(f"     [DEBUG] è¿›å…¥ CompilerOptimizer åˆ†æ”¯")
                                                    from src.core.compiler_optimizer import CompilerOptimizer
                                                    compiler_optimizer = CompilerOptimizer(compiler)
                                                    
                                                    error_msg = test_results.stderr or ""
                                                    success = await compiler_optimizer.optimize_dependencies(
                                                        target_agent,
                                                        analysis,
                                                        error_msg
                                                    )
                                                    
                                                    if success:
                                                        callback.on_log(f"    âœ… Compiler ä¼˜åŒ–: å·²æ›´æ–°ä¾èµ–é¡¹")
                                            
                                                else:
                                                    callback.on_log(f"     [DEBUG] æœªåŒ¹é…ä»»ä½•ä¼˜åŒ–å™¨åˆ†æ”¯")
                                                    callback.on_log(f"     [DEBUG] target='{fix_step.target}', rag_config={rag_config is not None}, tools_config={tools_config is not None}")
                                            
                                            except Exception as e:
                                                callback.on_log(f"    âš ï¸ ä¿®å¤æ­¥éª¤å¤±è´¥: {str(e)}")
                                                import traceback
                                                callback.on_log(f"    [DEBUG] å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()[:200]}")
                                    
                                    # 9. User confirmation
                                    if iteration < start_iteration + max_iterations - 1:
                                        confirm = input("\nç»§ç»­ä¸‹ä¸€æ¬¡è¿­ä»£? (y/n): ").strip().lower()
                                        if confirm != 'y':
                                            callback.on_log("ç”¨æˆ·é€‰æ‹©åœæ­¢è¿­ä»£")
                                            break
                                
                                except Exception as e:
                                    print(f"\nâŒ è¿­ä»£ {iteration} å¤±è´¥: {e}")
                                    import traceback
                                    traceback.print_exc()
                                    break
                            
                            # Final summary
                            print("\n" + "=" * 70)
                            evolution_summary = report_manager.generate_evolution_summary()
                            print(evolution_summary)
                            print(f"\nâœ… è¿­ä»£ä¼˜åŒ–å®Œæˆ!")
                            print(f"ğŸ“Š æŠ¥å‘Šå·²ä¿å­˜åˆ°: {target_agent / '.reports'}")
                        
                        elif idx == 0:
                            print("å·²å–æ¶ˆ")
                        else:
                            print("æ— æ•ˆåºå·")
                    except ValueError as e:
                        print(f"æ— æ•ˆè¾“å…¥: {e}")
                        import traceback
                        traceback.print_exc()
                    except Exception as e:
                        print(f"é”™è¯¯: {e}")
                        import traceback
                        traceback.print_exc()
                else:
                    print("   (ç©º) å°šæœªç”Ÿæˆä»»ä½• Agent")
            else:
                print("   (ç©º) agents ç›®å½•ä¸å­˜åœ¨")
        
        elif choice == "4":
            print("\nğŸ”§ API é…ç½®")
            print("   è¯·ç¼–è¾‘ .env æ–‡ä»¶ä»¥é…ç½® API è®¾ç½®")
            print(f"   ä½ç½®: {Path('.env').absolute()}")
        elif choice == "5":
            print("\nğŸ§ª æ­£åœ¨è¿è¡Œæµ‹è¯•...")
            print("   python tests/e2e/test_phase1_hello_world.py")
        elif choice == "6":
            print("\nğŸ“– æ–‡æ¡£")
            print("   README.md - é¡¹ç›®æ¦‚è§ˆ")
            print("   Agent Zeroé¡¹ç›®è®¡åˆ’ä¹¦.md - é¡¹ç›®è®¡åˆ’")
            print("   Agent_Zero_è¯¦ç»†å®æ–½è®¡åˆ’.md - å®æ–½ç»†èŠ‚")
        elif choice == "7":
            # ğŸ†• Phase 5: å¯¼å‡º Agent åˆ° Dify
            print("\nğŸ“¤ å¯¼å‡º Agent åˆ° Dify")
            print("=" * 50)

            agents_dir = Path("agents")
            if agents_dir.exists():
                agents = [d for d in agents_dir.iterdir() if d.is_dir() and not d.name.startswith('.')]

                if agents:
                    print("\nå¯ç”¨çš„ Agent:")
                    for i, agent in enumerate(agents, 1):
                        print(f"   {i}. {agent.name}")

                    try:
                        idx = int(input("\nè¯·é€‰æ‹© Agent ç¼–å· (0=å–æ¶ˆ): ").strip())
                        if 1 <= idx <= len(agents):
                            target_agent = agents[idx - 1]

                            # Load graph.json
                            graph_file = target_agent / "graph.json"
                            if not graph_file.exists():
                                print(f"âŒ æœªæ‰¾åˆ° graph.json: {graph_file}")
                                continue

                            print(f"\nğŸ“‚ Agent: {target_agent.name}")
                            print(f"ğŸ“ è·¯å¾„: {target_agent}")

                            # Import export modules
                            from src.exporters import export_to_dify, validate_for_dify
                            from src.utils.readme_generator import generate_readme
                            from src.schemas.graph_structure import GraphStructure
                            import json

                            # Load graph
                            with open(graph_file, 'r', encoding='utf-8') as f:
                                graph_data = json.load(f)
                            graph = GraphStructure.model_validate(graph_data)

                            # Validate
                            print("\nğŸ” éªŒè¯ Graph...")
                            valid, warnings = validate_for_dify(graph)

                            if valid:
                                print("âœ… Graph éªŒè¯é€šè¿‡")
                            else:
                                print("âŒ Graph éªŒè¯å¤±è´¥")

                            if warnings:
                                print("\nâš ï¸  è­¦å‘Šä¿¡æ¯:")
                                for warning in warnings:
                                    print(f"  - {warning}")

                            # Export options
                            print("\nè¯·é€‰æ‹©å¯¼å‡ºé€‰é¡¹:")
                            print("  1. å¯¼å‡º Dify YAML")
                            print("  2. ç”Ÿæˆ README")
                            print("  3. ä¸¤è€…éƒ½å¯¼å‡º")
                            print("  0. å–æ¶ˆ")

                            export_choice = input("\nè¯·é€‰æ‹© (0-3): ").strip()

                            if export_choice in ["1", "3"]:
                                # Export Dify YAML
                                output_dir = Path("exports") / target_agent.name
                                output_dir.mkdir(parents=True, exist_ok=True)

                                dify_path = export_to_dify(
                                    graph=graph,
                                    agent_name=target_agent.name,
                                    output_path=output_dir / f"{target_agent.name}_dify.yml"
                                )

                                print(f"\nâœ… Dify YAML å·²å¯¼å‡º: {dify_path}")
                                print(f"   æ–‡ä»¶å¤§å°: {dify_path.stat().st_size} å­—èŠ‚")

                            if export_choice in ["2", "3"]:
                                # Generate README
                                output_dir = Path("exports") / target_agent.name
                                output_dir.mkdir(parents=True, exist_ok=True)

                                readme_path = generate_readme(
                                    agent_name=target_agent.name,
                                    graph=graph,
                                    output_path=output_dir / "README.md"
                                )

                                print(f"\nâœ… README å·²ç”Ÿæˆ: {readme_path}")
                                print(f"   æ–‡ä»¶å¤§å°: {readme_path.stat().st_size} å­—èŠ‚")

                            if export_choice in ["1", "2", "3"]:
                                print(f"\nğŸ“ å¯¼å‡ºç›®å½•: {output_dir}")
                                print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
                                print("   1. è®¿é—® https://cloud.dify.ai")
                                print("   2. åˆ›å»ºåº”ç”¨ â†’ Chatflow")
                                print("   3. å¯¼å…¥ DSL â†’ ä¸Šä¼  YAML æ–‡ä»¶")
                                if any(node.type == "rag" for node in graph.nodes):
                                    print("   4. æ‰‹åŠ¨æ·»åŠ  Knowledge Retrieval èŠ‚ç‚¹ï¼ˆRAG èŠ‚ç‚¹å·²è·³è¿‡ï¼‰")

                        elif idx == 0:
                            print("å·²å–æ¶ˆ")
                        else:
                            print("æ— æ•ˆåºå·")
                    except ValueError:
                        print("æ— æ•ˆè¾“å…¥")
                    except Exception as e:
                        print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
                        import traceback
                        traceback.print_exc()
                else:
                    print("   (ç©º) å°šæœªç”Ÿæˆä»»ä½• Agent")
            else:
                print("   (ç©º) agents ç›®å½•ä¸å­˜åœ¨")

        elif choice == "8":
            # ğŸ†• Phase 5: å¯åŠ¨ Web UI
            print("\nğŸ¨ å¯åŠ¨ Web UI")
            print("=" * 50)

            # Check if streamlit is installed
            try:
                import streamlit
                print(f"âœ… Streamlit å·²å®‰è£… (ç‰ˆæœ¬: {streamlit.__version__})")
            except ImportError:
                print("âŒ Streamlit æœªå®‰è£…")
                print("\nè¯·å…ˆå®‰è£…ä¾èµ–:")
                print("   python install_dependencies.py")
                print("   æˆ–")
                print("   pip install streamlit plotly")
                continue

            print("\næ­£åœ¨å¯åŠ¨ Streamlit UI...")
            print("æµè§ˆå™¨å°†è‡ªåŠ¨æ‰“å¼€ï¼Œæˆ–æ‰‹åŠ¨è®¿é—®: http://localhost:8501")
            print("\næŒ‰ Ctrl+C åœæ­¢æœåŠ¡å™¨")
            print()

            import subprocess
            try:
                # Use python -m to avoid PATH issues
                subprocess.run([sys.executable, "-m", "streamlit", "run", "app.py"])
            except KeyboardInterrupt:
                print("\n\nâœ… UI å·²åœæ­¢")
            except Exception as e:
                print(f"\nâŒ å¯åŠ¨å¤±è´¥: {e}")
                print("\nè¯·å°è¯•æ‰‹åŠ¨å¯åŠ¨:")
                print("   python -m streamlit run app.py")

        elif choice == "9":
            print(f"\n{t('goodbye')}")
            break
        else:
            print(f"\n{t('invalid_option')}")
        
        input(f"\n{t('press_enter')}")


if __name__ == "__main__":
    # Parse command line arguments
    parser = argparse.ArgumentParser(
        description="Agent Zero v8.0 - Intelligent Agent Factory",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument(
        '--debug',
        action='store_true',
        help='Enable debug logging (shows detailed execution traces)'
    )
    parser.add_argument(
        '--lang',
        choices=['zh', 'en'],
        help='Set language: zh (Chinese) or en (English)'
    )
    
    args = parser.parse_args()
    
    # Set debug mode globally
    set_debug_mode(args.debug)
    
    # Select language
    selected_lang = select_language(args)
    
    # Store language globally (will be used by i18n module)
    os.environ['AGENT_ZERO_LANG'] = selected_lang
    set_language(selected_lang)
    
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print(f"\n\n{t('interrupted')}")
    except Exception as e:
        print(f"\n{t('error')}: {e}")
        sys.exit(1)
