"""
Integration Test for Phase 3 Blueprint Simulation System

This test verifies the complete workflow:
1. PM Clarifier + Planner
2. Graph Designer (3-step method)
3. Simulator (with real LLM)
4. Compiler

Run with: python tests/integration/test_phase3_integration.py
"""

import asyncio
import sys
from pathlib import Path
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Add project root to path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.core.pm import PM
from src.core.graph_designer import GraphDesigner
from src.core.simulator import Simulator
from src.core.compiler import Compiler
from src.llm import BuilderClient
from src.schemas import ToolsConfig, RAGConfig


async def test_simple_chat_agent():
    """Test 1: Simple chat agent (Sequential pattern)"""
    print("\n" + "=" * 60)
    print("Test 1: Simple Chat Agent (Sequential Pattern)")
    print("=" * 60)

    # Initialize components
    builder = BuilderClient.from_env()  # Load from .env
    pm = PM(builder)
    designer = GraphDesigner(builder)
    simulator = Simulator(builder)
    compiler = Compiler(project_root / "src" / "templates")

    # Step 1: PM Analysis
    print("\n[Step 1] PM åˆ†æéœ€æ±‚...")
    user_query = "åˆ›å»ºä¸€ä¸ªç®€å•çš„èŠå¤©åŠ©æ‰‹ï¼Œèƒ½å¤Ÿå›ç­”ç”¨æˆ·çš„é—®é¢˜"

    project_meta = await pm.analyze_with_clarification_loop(
        user_query=user_query, chat_history=[], file_paths=None
    )

    print(f"âœ“ Agent Name: {project_meta.agent_name}")
    print(f"âœ“ Status: {project_meta.status}")
    print(f"âœ“ Complexity: {project_meta.complexity_score}/10")

    if project_meta.status == "clarifying":
        print("âš ï¸ éœ€è¦æ¾„æ¸…:")
        for q in project_meta.clarification_questions:
            print(f"  - {q}")
        return False

    # Step 2: Graph Designer
    print("\n[Step 2] Graph Designer è®¾è®¡å›¾ç»“æ„...")
    graph = await designer.design_graph(
        project_meta=project_meta, tools_config=ToolsConfig(enabled_tools=[]), rag_config=None
    )

    print(f"âœ“ Pattern: {graph.pattern.pattern_type.value}")
    print(f"âœ“ Nodes: {len(graph.nodes)} ({', '.join([n.id for n in graph.nodes])})")
    print(f"âœ“ State Fields: {len(graph.state_schema.fields)}")

    # Step 3: Simulator (with real LLM)
    print("\n[Step 3] Simulator æ²™ç›˜æ¨æ¼” (ä½¿ç”¨çœŸå® LLM)...")
    sim_result = await simulator.simulate(
        graph=graph, sample_input="ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±", use_llm=True  # Use real LLM
    )

    print(f"âœ“ Success: {sim_result.success}")
    print(f"âœ“ Total Steps: {sim_result.total_steps}")
    print(f"âœ“ Issues: {len(sim_result.issues)}")

    if sim_result.issues:
        for issue in sim_result.issues:
            print(f"  [{issue.severity}] {issue.description}")

    print("\næ‰§è¡Œè½¨è¿¹:")
    print(sim_result.execution_trace)

    # Step 4: Compiler
    print("\n[Step 4] Compiler ç”Ÿæˆä»£ç ...")
    output_dir = project_root / "agents" / "test_simple_chat"

    compile_result = compiler.compile(
        project_meta=project_meta,
        graph=graph,
        rag_config=None,
        tools_config=ToolsConfig(enabled_tools=[]),
        output_dir=output_dir,
    )

    print(f"âœ“ Compilation: {'Success' if compile_result.success else 'Failed'}")
    print(f"âœ“ Output Dir: {compile_result.output_dir}")
    print(f"âœ“ Generated Files: {', '.join(compile_result.generated_files)}")

    return sim_result.success and compile_result.success


async def test_reflection_agent():
    """Test 2: Writing assistant with reflection (Reflection pattern)"""
    print("\n" + "=" * 60)
    print("Test 2: Writing Assistant (Reflection Pattern)")
    print("=" * 60)

    builder = BuilderClient.from_env()  # Load from .env
    pm = PM(builder)
    designer = GraphDesigner(builder)
    simulator = Simulator(builder)
    compiler = Compiler(project_root / "src" / "templates")

    # Step 1: PM Analysis
    print("\n[Step 1] PM åˆ†æéœ€æ±‚...")
    user_query = "åˆ›å»ºä¸€ä¸ªå†™ä½œåŠ©æ‰‹ï¼Œèƒ½å¤Ÿç”Ÿæˆæ–‡ç« å¹¶æ ¹æ®åé¦ˆè¿›è¡Œä¼˜åŒ–æ”¹è¿›"

    project_meta = await pm.analyze_with_clarification_loop(
        user_query=user_query, chat_history=[], file_paths=None
    )

    print(f"âœ“ Agent Name: {project_meta.agent_name}")
    print(f"âœ“ Complexity: {project_meta.complexity_score}/10")

    if project_meta.execution_plan:
        print(f"âœ“ Execution Plan: {len(project_meta.execution_plan)} steps")
        for step in project_meta.execution_plan:
            print(f"  {step.step}. [{step.role}] {step.goal}")

    # Step 2: Graph Designer
    print("\n[Step 2] Graph Designer è®¾è®¡å›¾ç»“æ„...")
    graph = await designer.design_graph(
        project_meta=project_meta, tools_config=ToolsConfig(enabled_tools=[]), rag_config=None
    )

    print(f"âœ“ Pattern: {graph.pattern.pattern_type.value}")
    print(f"âœ“ Nodes: {', '.join([n.id for n in graph.nodes])}")
    print(f"âœ“ Max Iterations: {graph.pattern.max_iterations}")

    # Check for reflection-specific state fields
    has_draft = graph.state_schema.has_field("draft")
    has_feedback = graph.state_schema.has_field("feedback")
    print(f"âœ“ Reflection State: draft={has_draft}, feedback={has_feedback}")

    # Step 3: Simulator
    print("\n[Step 3] Simulator æ²™ç›˜æ¨æ¼” (ä½¿ç”¨çœŸå® LLM)...")
    sim_result = await simulator.simulate(
        graph=graph,
        sample_input="å†™ä¸€ç¯‡å…³äºäººå·¥æ™ºèƒ½çš„çŸ­æ–‡",
        use_llm=True,
        max_steps=15,  # Allow more steps for iteration
    )

    print(f"âœ“ Success: {sim_result.success}")
    print(f"âœ“ Total Steps: {sim_result.total_steps}")
    print(f"âœ“ Issues: {len(sim_result.issues)}")

    # Show final state
    if "iteration_count" in sim_result.final_state:
        print(f"âœ“ Iterations: {sim_result.final_state['iteration_count']}")

    print("\næ‰§è¡Œè½¨è¿¹ (å‰10æ­¥):")
    lines = sim_result.execution_trace.split("\n")[:12]
    print("\n".join(lines))

    # Step 4: Compiler
    print("\n[Step 4] Compiler ç”Ÿæˆä»£ç ...")
    output_dir = project_root / "agents" / "test_reflection_writer"

    compile_result = compiler.compile(
        project_meta=project_meta,
        graph=graph,
        rag_config=None,
        tools_config=ToolsConfig(enabled_tools=[]),
        output_dir=output_dir,
    )

    print(f"âœ“ Compilation: {'Success' if compile_result.success else 'Failed'}")
    print(f"âœ“ Generated Files: {len(compile_result.generated_files)}")

    return sim_result.success and compile_result.success


async def test_rag_agent():
    """Test 3: RAG-based Q&A agent"""
    print("\n" + "=" * 60)
    print("Test 3: RAG Q&A Agent")
    print("=" * 60)

    builder = BuilderClient.from_env()  # Load from .env
    pm = PM(builder)
    designer = GraphDesigner(builder)
    simulator = Simulator(builder)
    compiler = Compiler(project_root / "src" / "templates")

    # Step 1: PM Analysis
    print("\n[Step 1] PM åˆ†æéœ€æ±‚...")
    user_query = "åˆ›å»ºä¸€ä¸ªèƒ½å¤Ÿå›ç­”é¡¹ç›®æ–‡æ¡£ç›¸å…³é—®é¢˜çš„æ™ºèƒ½åŠ©æ‰‹"
    file_paths = [project_root / "README.md"]

    project_meta = await pm.analyze_with_clarification_loop(
        user_query=user_query, chat_history=[], file_paths=file_paths
    )

    print(f"âœ“ Agent Name: {project_meta.agent_name}")
    print(f"âœ“ Has RAG: {project_meta.has_rag}")
    print(f"âœ“ Files: {len(project_meta.file_paths or [])}")

    # Step 2: Graph Designer
    print("\n[Step 2] Graph Designer è®¾è®¡å›¾ç»“æ„...")

    # Create RAG config
    rag_config = RAGConfig(
        vector_store="chroma",
        embedding_provider="ollama",
        embedding_model_name="nomic-embed-text",
        chunk_size=500,
        chunk_overlap=50,
        k_retrieval=3,
    )

    graph = await designer.design_graph(
        project_meta=project_meta, tools_config=ToolsConfig(enabled_tools=[]), rag_config=rag_config
    )

    print(f"âœ“ Pattern: {graph.pattern.pattern_type.value}")
    print(f"âœ“ Nodes: {', '.join([n.id for n in graph.nodes])}")

    # Check for RAG node
    has_rag_node = any(n.type == "rag" for n in graph.nodes)
    print(f"âœ“ Has RAG Node: {has_rag_node}")

    # Step 3: Simulator
    print("\n[Step 3] Simulator æ²™ç›˜æ¨æ¼”...")
    sim_result = await simulator.simulate(
        graph=graph, sample_input="è¿™ä¸ªé¡¹ç›®æ˜¯åšä»€ä¹ˆçš„ï¼Ÿ", use_llm=True
    )

    print(f"âœ“ Success: {sim_result.success}")
    print(f"âœ“ Total Steps: {sim_result.total_steps}")

    # Step 4: Compiler
    print("\n[Step 4] Compiler ç”Ÿæˆä»£ç ...")
    output_dir = project_root / "agents" / "test_rag_qa"

    compile_result = compiler.compile(
        project_meta=project_meta,
        graph=graph,
        rag_config=rag_config,
        tools_config=ToolsConfig(enabled_tools=[]),
        output_dir=output_dir,
    )

    print(f"âœ“ Compilation: {'Success' if compile_result.success else 'Failed'}")

    # Check for RAG-specific files
    if compile_result.success:
        agent_file = output_dir / "agent.py"
        if agent_file.exists():
            content = agent_file.read_text(encoding="utf-8")
            has_rag_code = "rag_retriever" in content
            print(f"âœ“ RAG Code Generated: {has_rag_code}")

    return sim_result.success and compile_result.success


async def test_pm_clarification():
    """Test 4: PM Clarification for vague requirements"""
    print("\n" + "=" * 60)
    print("Test 4: PM Clarification (Vague Requirements)")
    print("=" * 60)

    builder = BuilderClient.from_env()  # Load from .env
    pm = PM(builder)

    print("\n[Test] æ¨¡ç³Šéœ€æ±‚: 'å¸®æˆ‘å†™ä¸ªçˆ¬è™«'")

    project_meta = await pm.analyze_with_clarification_loop(
        user_query="å¸®æˆ‘å†™ä¸ªçˆ¬è™«", chat_history=[], file_paths=None
    )

    print(f"âœ“ Status: {project_meta.status}")

    if project_meta.status == "clarifying":
        print(f"âœ“ Clarification Needed: True")
        print(f"âœ“ Questions ({len(project_meta.clarification_questions or [])}):")
        for i, q in enumerate(project_meta.clarification_questions or [], 1):
            print(f"  {i}. {q}")
        return True
    else:
        print("âš ï¸ Expected clarification but got ready status")
        return False


async def run_all_tests():
    """Run all integration tests"""
    print("\n" + "=" * 80)
    print("Phase 3 Integration Tests - Real API Calls")
    print("=" * 80)

    results = {}

    try:
        # Test 1: Simple Chat
        results["simple_chat"] = await test_simple_chat_agent()

        # Test 2: Reflection
        results["reflection"] = await test_reflection_agent()

        # Test 3: RAG
        results["rag"] = await test_rag_agent()

        # Test 4: PM Clarification
        results["clarification"] = await test_pm_clarification()

    except Exception as e:
        print(f"\nâŒ Test failed with error: {e}")
        import traceback

        traceback.print_exc()
        return False

    # Summary
    print("\n" + "=" * 80)
    print("Test Summary")
    print("=" * 80)

    for test_name, result in results.items():
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"{status} - {test_name}")

    total = len(results)
    passed = sum(results.values())

    print(f"\nTotal: {passed}/{total} tests passed")

    return all(results.values())


if __name__ == "__main__":
    print("Starting Phase 3 Integration Tests...")
    print("This will make real API calls to test the complete workflow.\n")

    success = asyncio.run(run_all_tests())

    if success:
        print("\nğŸ‰ All integration tests passed!")
        sys.exit(0)
    else:
        print("\nâŒ Some tests failed")
        sys.exit(1)
