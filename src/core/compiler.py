"""Compiler module for generating agent code from JSON configurations."""

import json
from pathlib import Path
from typing import Optional
from datetime import datetime
from jinja2 import Environment, FileSystemLoader, Template
from pydantic import BaseModel, Field

from ..schemas import GraphStructure, RAGConfig, ToolsConfig, ProjectMeta
from ..tools.definitions import CURATED_TOOLS
from ..utils.config_utils import atomic_write_json


class CompileResult(BaseModel):
    """Result of compilation process."""

    success: bool = Field(..., description="Whether compilation succeeded")
    output_dir: Path = Field(..., description="Output directory path")
    generated_files: list[str] = Field(default_factory=list, description="List of generated files")
    error_message: Optional[str] = Field(
        default=None, description="Error message if compilation failed"
    )


class Compiler:
    """Compiler for generating agent code from JSON configurations.

    Transforms JSON intermediate representation into executable Python code
    using Jinja2 templates.
    """

    def __init__(self, template_dir: Path):
        """Initialize compiler with template directory.

        Args:
            template_dir: Path to directory containing Jinja2 templates
        """
        self.template_dir = template_dir
        self.env = Environment(
            loader=FileSystemLoader(template_dir),
            trim_blocks=True,
            lstrip_blocks=True,
        )

        # ğŸ†• Add custom filter for sanitizing collection names
        def sanitize_collection_name(name: str) -> str:
            """Replace non-ASCII and special characters with underscores"""
            import re

            # 1. Replace invalid chars with underscores
            clean = re.sub(r"[^a-zA-Z0-9._-]", "_", name)

            # 2. Ensure start/end with alphanumeric
            if not clean or not clean[0].isalnum():
                clean = "agent" + clean
            if not clean[-1].isalnum():
                clean = clean + "docs"

            # 3. Ensure length (3-63) - Chroma allows 512 but safe limit is better
            if len(clean) < 3:
                clean = clean + "_data"

            # 4. Collapse multiple underscores
            clean = re.sub(r"_{2,}", "_", clean)

            return clean

        self.env.filters["sanitize_collection_name"] = sanitize_collection_name

    def _prepare_tool_context(self, enabled_tools: list[str]) -> dict:
        """é¢„å¤„ç†å·¥å…·å…ƒæ•°æ®,ç”Ÿæˆæ¨¡æ¿æ‰€éœ€çš„æ¸…æ´—æ•°æ® (æ–¹æ¡ˆ A+)

        Args:
            enabled_tools: å¯ç”¨çš„å·¥å…· ID åˆ—è¡¨

        Returns:
            {
                "tool_imports": ["from langchain_community.tools import TavilySearchResults"],
                "tool_inits": [
                    {
                        "name": "Tavily Search",
                        "id": "tavily_search",
                        "class_name": "TavilySearchResults",
                        "params": 'api_key=os.getenv("TAVILY_API_KEY"), max_results=5',
                        "env_var": "TAVILY_API_KEY"
                    }
                ]
            }
        """
        tool_imports = set()
        tool_inits = []

        for tool_id in enabled_tools:
            # ä» CURATED_TOOLS è·å–å…ƒæ•°æ®
            meta = next((t for t in CURATED_TOOLS if t["id"] == tool_id), None)
            if not meta:
                print(f"âš ï¸ Warning: Tool '{tool_id}' not found in CURATED_TOOLS")
                continue

            # 1. è§£æå¯¼å…¥è·¯å¾„ (Python å¤„ç†,ä¸åœ¨æ¨¡æ¿é‡Œåš)
            import_path = meta.get("import_path")
            if not import_path:
                print(f"âš ï¸ Warning: Tool '{tool_id}' missing import_path")
                continue

            try:
                module_path, class_name = import_path.rsplit(".", 1)
            except ValueError:
                print(f"âš ï¸ Warning: Invalid import_path for '{tool_id}': {import_path}")
                continue

            tool_imports.add(f"from {module_path} import {class_name}")

            # 2. å‡†å¤‡åˆå§‹åŒ–å‚æ•°
            init_params = []

            # å¤„ç† API Key
            if meta.get("requires_api_key"):
                env_var = meta.get("env_var")
                if env_var:
                    init_params.append(f'api_key=os.getenv("{env_var}")')

            # å¤„ç†é»˜è®¤å‚æ•° (ä» args_schema æå–)
            args_schema = meta.get("args_schema", {})
            properties = args_schema.get("properties", {})

            for prop_name, prop_def in properties.items():
                if "default" in prop_def:
                    default_value = prop_def["default"]
                    if isinstance(default_value, str):
                        init_params.append(f'{prop_name}="{default_value}"')
                    else:
                        init_params.append(f"{prop_name}={default_value}")

            tool_inits.append(
                {
                    "name": meta.get("name", tool_id),
                    "id": tool_id,
                    "class_name": class_name,
                    "params": ", ".join(init_params),
                    "env_var": meta.get("env_var"),
                }
            )

        return {"tool_imports": sorted(list(tool_imports)), "tool_inits": tool_inits}

    def compile(
        self,
        project_meta: ProjectMeta,
        graph: GraphStructure,
        rag_config: Optional[RAGConfig],
        tools_config: ToolsConfig,
        output_dir: Path,
    ) -> CompileResult:
        """Compile JSON configurations into executable agent code.

        Args:
            project_meta: Project metadata
            graph: Graph structure definition
            rag_config: RAG configuration (optional)
            tools_config: Tools configuration
            output_dir: Output directory for generated files

        Returns:
            CompileResult with success status and generated files
        """
        try:
            # Create output directory
            output_dir.mkdir(parents=True, exist_ok=True)
            generated_files = []

            # Prepare template context
            context = {
                "timestamp": datetime.now().isoformat(),
                "agent_name": project_meta.agent_name,
                "description": project_meta.description,
                "has_rag": project_meta.has_rag,
                "has_tools": len(tools_config.enabled_tools) > 0,
                # New Phase 3 fields
                "pattern": graph.pattern,
                "state_schema": graph.state_schema,
                # Graph structure
                "nodes": graph.nodes,
                "edges": graph.edges,
                "conditional_edges": graph.conditional_edges,
                "entry_point": graph.entry_point,
                "entry_point": graph.entry_point,
                # Tools and config
                "enabled_tools": tools_config.enabled_tools,
                "enabled_tools_meta": [
                    t for t in CURATED_TOOLS if t["id"] in tools_config.enabled_tools
                ],
                "agent_type": project_meta.task_type,
                "language": project_meta.language,
                "custom_instructions": project_meta.description,
                "file_paths": project_meta.file_paths or [],
            }

            # Add RAG config if present
            if rag_config:
                context["rag_config"] = rag_config

            # ğŸ†• æ–¹æ¡ˆ A+: é¢„å¤„ç†å·¥å…·ä¸Šä¸‹æ–‡
            if len(tools_config.enabled_tools) > 0:
                tool_context = self._prepare_tool_context(tools_config.enabled_tools)
                context["tool_imports"] = tool_context["tool_imports"]
                context["tool_inits"] = tool_context["tool_inits"]
            else:
                context["tool_imports"] = []
                context["tool_inits"] = []

            # Generate agent.py
            agent_template = self.env.get_template("agent_template.py.j2")
            agent_code = agent_template.render(**context)

            # Format code with black (if available)
            try:
                import black

                agent_code = black.format_str(agent_code, mode=black.Mode())
            except ImportError:
                pass  # Black not available, skip formatting

            agent_file = output_dir / "agent.py"
            agent_file.write_text(agent_code, encoding="utf-8")
            generated_files.append("agent.py")

            # Generate prompts.yaml
            prompts_template = self.env.get_template("prompts_template.yaml.j2")
            prompts_content = prompts_template.render(**context)
            prompts_file = output_dir / "prompts.yaml"
            prompts_file.write_text(prompts_content, encoding="utf-8")
            generated_files.append("prompts.yaml")

            # Generate requirements.txt
            requirements = self._generate_requirements(
                has_rag=project_meta.has_rag,
                has_tools=len(tools_config.enabled_tools) > 0,
                rag_config=rag_config,
                file_paths=project_meta.file_paths,
            )
            requirements_file = output_dir / "requirements.txt"
            requirements_file.write_text(requirements, encoding="utf-8")
            generated_files.append("requirements.txt")

            # Generate .env.template
            env_template = self._generate_env_template()
            env_file = output_dir / ".env.template"
            env_file.write_text(env_template, encoding="utf-8")
            generated_files.append(".env.template")

            # ğŸ†• Generate real .env with current config (Auto-configuration)
            env_content = self._generate_env_file_content()
            real_env_file = output_dir / ".env"
            real_env_file.write_text(env_content, encoding="utf-8")
            generated_files.append(".env")

            # ğŸ†• Phase 4: ç”Ÿæˆ pip.conf (ä¼˜åŒ– 2 - é¢„å®‰è£…)
            pip_config = self._generate_pip_config()
            pip_config_file = output_dir / "pip.conf"
            pip_config_file.write_text(pip_config, encoding="utf-8")
            generated_files.append("pip.conf")

            # ğŸ†• Phase 4: ç”Ÿæˆå®‰è£…è„šæœ¬
            install_sh = self._generate_install_script_sh()
            install_sh_file = output_dir / "install.sh"
            install_sh_file.write_text(install_sh, encoding="utf-8")
            # è®¾ç½®å¯æ‰§è¡Œæƒé™ (Unix/Linux/Mac)
            try:
                import os

                os.chmod(install_sh_file, 0o755)
            except Exception:
                pass  # Windows ä¸éœ€è¦
            generated_files.append("install.sh")

            install_bat = self._generate_install_script_bat()
            install_bat_file = output_dir / "install.bat"
            install_bat_file.write_text(install_bat, encoding="utf-8")
            generated_files.append("install.bat")

            # Save graph.json for UI visualization
            graph_file = output_dir / "graph.json"
            graph_file.write_text(graph.model_dump_json(indent=2), encoding="utf-8")
            generated_files.append("graph.json")

            # ğŸ†• Save rag_config.json if RAG is enabled
            if rag_config:
                atomic_write_json(output_dir / "rag_config.json", rag_config.model_dump())
                generated_files.append("rag_config.json")

            # ğŸ†• Save tools_config.json if tools are enabled
            if tools_config and len(tools_config.enabled_tools) > 0:
                atomic_write_json(output_dir / "tools_config.json", tools_config.model_dump())
                generated_files.append("tools_config.json")

            return CompileResult(
                success=True, output_dir=output_dir, generated_files=generated_files
            )

        except Exception as e:
            return CompileResult(
                success=False,
                output_dir=output_dir,
                error_message=f"Compilation failed: {str(e)}",
            )

    def _generate_requirements(
        self,
        has_rag: bool,
        has_tools: bool,
        rag_config: Optional[RAGConfig] = None,
        file_paths: Optional[list] = None,
        include_testing: bool = True,  # ğŸ†• Phase 4: æ·»åŠ æµ‹è¯•ä¾èµ–å¼€å…³
    ) -> str:
        """Generate requirements.txt content based on features.

        Args:
            has_rag: Whether RAG is enabled
            has_tools: Whether tools are enabled
            rag_config: RAG configuration (optional)
            file_paths: List of file paths for document loading
            include_testing: Whether to include DeepEval testing dependencies

        Returns:
            Requirements.txt content as string
        """
        requirements = [
            "# Core dependencies",
            "langchain>=0.2.0",
            "langgraph>=0.2.28",
            "langchain-openai>=0.1.0",
            "python-dotenv>=1.0.0",
            "pyyaml>=6.0.1",
        ]

        if has_rag and rag_config:
            requirements.extend(
                [
                    "",
                    "# RAG dependencies",
                    "langchain-community>=0.2.0",
                    "tiktoken>=0.5.0",  # Token counting
                ]
            )

            # Vector store dependencies
            if rag_config.vector_store == "chroma":
                requirements.append("chromadb>=0.4.22")
            elif rag_config.vector_store == "faiss":
                requirements.append("faiss-cpu>=1.7.4")
            elif rag_config.vector_store == "pgvector":
                requirements.append("pgvector>=0.2.0")
                requirements.append("psycopg2-binary>=2.9.0")

            # Embedding model dependencies
            # Include all providers since we support runtime switching via env vars
            requirements.append("langchain-openai>=0.1.0")  # For OpenAI embeddings
            requirements.append("langchain-ollama>=0.1.0")  # For Ollama embeddings
            # HuggingFace is optional, only add if explicitly configured
            if rag_config.embedding_provider == "huggingface":
                requirements.append("sentence-transformers>=2.2.0")

            # Document loader dependencies (based on file types)
            if file_paths and len(file_paths) > 0:
                has_pdf = any(str(f).lower().endswith(".pdf") for f in file_paths)
                has_docx = any(str(f).lower().endswith((".docx", ".doc")) for f in file_paths)
                has_md = any(str(f).lower().endswith(".md") for f in file_paths)

                if has_pdf:
                    requirements.append("pypdf>=3.17.0")
                if has_docx:
                    requirements.append("python-docx>=1.1.0")
                if has_md:
                    requirements.append("unstructured>=0.12.0")
                    requirements.append("markdown>=3.5.0")  # Required by unstructured for markdown
            else:
                # Add all loaders if no file paths specified
                requirements.extend(
                    [
                        "pypdf>=3.17.0",
                        "python-docx>=1.1.0",
                        "markdown>=3.5.0",  # Required by unstructured for markdown
                    ]
                )

            # [v7.2 Update] Default Dependencies for Evolution Capability
            # Always install these so the Optimizer can switch to them at runtime
            requirements.append("rank-bm25>=0.2.2")
            requirements.append("flashrank>=0.2.0")

            # Hybrid search dependencies (Legacy check for jieba)
            if hasattr(rag_config, "language") and "zh" in str(rag_config.language).lower():
                requirements.append("jieba>=0.42.1")

            # Additional Reranker dependencies (if specific provider selected)
            if rag_config.reranker_enabled and rag_config.reranker_provider:
                if rag_config.reranker_provider == "cohere":
                    requirements.append("cohere>=4.0.0")
                elif rag_config.reranker_provider == "bge":
                    requirements.append("sentence-transformers>=2.2.0")

        if has_tools:
            requirements.extend(
                [
                    "",
                    "# Tool dependencies",
                    "langchain-community>=0.2.0",
                ]
            )

        # ğŸ†• Phase 4: DeepEval æµ‹è¯•ä¾èµ– (ä¼˜åŒ– 2 - é¢„å®‰è£…)
        if include_testing:
            requirements.extend(
                [
                    "",
                    "# Testing dependencies (Phase 4 - DeepEval)",
                    "deepeval>=0.21.0",
                    "pytest>=7.4.0",
                    "pytest-json-report>=1.5.0",
                    "langchain-community>=0.2.0",  # Required for IteraAgentJudge adapters
                ]
            )

        return "\n".join(requirements)

    def _generate_env_template(self) -> str:
        """Generate .env.template content.

        Returns:
            Environment template content as string
        """
        return """# IteraAgent - Generated Agent Configuration
# ==========================================

# Runtime API Configuration (ç”¨äºç”Ÿæˆçš„ Agent è¿è¡Œæ—¶)
RUNTIME_PROVIDER=openai
RUNTIME_MODEL=deepseek-chat
RUNTIME_API_KEY=your_api_key_here
RUNTIME_BASE_URL=https://api.deepseek.com
RUNTIME_TIMEOUT=30
RUNTIME_TEMPERATURE=0.7

# Embedding Configuration (ç”¨äº RAG å‘é‡åŒ–)
EMBEDDING_PROVIDER=ollama
EMBEDDING_MODEL_NAME=nomic-embed-text
EMBEDDING_BASE_URL=http://localhost:11434
# EMBEDDING_API_KEY ä¸éœ€è¦ï¼ˆOllama æœ¬åœ°è¿è¡Œï¼‰

# Judge API Configuration (ç”¨äº DeepEval æµ‹è¯•è¯„ä¼°)
# å¦‚æœæœªé…ç½®,DeepEval å°†ä½¿ç”¨ Runtime API
JUDGE_PROVIDER=openai
JUDGE_MODEL=deepseek-chat
JUDGE_API_KEY=your_api_key_here
JUDGE_BASE_URL=https://api.deepseek.com
JUDGE_TIMEOUT=60
JUDGE_TEMPERATURE=0.0
"""

    def _generate_env_file_content(self) -> str:
        """Generate .env content populated with current system configuration.

        Returns:
            Populated .env content as string
        """
        import os
        from datetime import datetime

        # Helper to get env with default (fallback to sensible defaults if env not set)
        def get_val(key, default):
            return os.getenv(key, default)

        return f"""# IteraAgent - Auto-generated Configuration
# Generated from system configuration on {datetime.now().isoformat()}
# This file is auto-populated with your current environment settings.

# Runtime API Configuration
RUNTIME_PROVIDER={get_val("RUNTIME_PROVIDER", "openai")}
RUNTIME_MODEL={get_val("RUNTIME_MODEL", "deepseek-chat")}
RUNTIME_API_KEY={get_val("RUNTIME_API_KEY", "")}
RUNTIME_BASE_URL={get_val("RUNTIME_BASE_URL", "https://api.deepseek.com")}
RUNTIME_TIMEOUT={get_val("RUNTIME_TIMEOUT", "30")}
RUNTIME_TEMPERATURE={get_val("RUNTIME_TEMPERATURE", "0.7")}

# Embedding Configuration
EMBEDDING_PROVIDER={get_val("EMBEDDING_PROVIDER", "ollama")}
EMBEDDING_MODEL_NAME={get_val("EMBEDDING_MODEL_NAME", get_val("EMBEDDING_MODEL", "nomic-embed-text"))}
EMBEDDING_BASE_URL={get_val("EMBEDDING_BASE_URL", "http://localhost:11434")}
EMBEDDING_API_KEY={get_val("EMBEDDING_API_KEY", "")}

# Judge API Configuration (ç”¨äº DeepEval æµ‹è¯•è¯„ä¼°)
# å¦‚æœæœªé…ç½®,DeepEval å°†ä½¿ç”¨ Runtime API
JUDGE_PROVIDER={get_val("JUDGE_PROVIDER", get_val("RUNTIME_PROVIDER", "openai"))}
JUDGE_MODEL={get_val("JUDGE_MODEL", get_val("RUNTIME_MODEL", "deepseek-chat"))}
JUDGE_API_KEY={get_val("JUDGE_API_KEY", get_val("RUNTIME_API_KEY", ""))}
JUDGE_BASE_URL={get_val("JUDGE_BASE_URL", get_val("RUNTIME_BASE_URL", "https://api.deepseek.com"))}
JUDGE_TIMEOUT={get_val("JUDGE_TIMEOUT", "60")}
JUDGE_TEMPERATURE={get_val("JUDGE_TEMPERATURE", "0.0")}
"""

    def _generate_pip_config(self) -> str:
        """ğŸ†• Phase 4: ç”Ÿæˆ pip.conf (ä½¿ç”¨å›½å†…é•œåƒæº)

        Returns:
            pip.conf content as string
        """
        return """[global]
index-url = https://pypi.tuna.tsinghua.edu.cn/simple
[install]
trusted-host = pypi.tuna.tsinghua.edu.cn
"""

    def _generate_install_script_sh(self) -> str:
        """ğŸ†• Phase 4: ç”Ÿæˆ Linux/Mac å®‰è£…è„šæœ¬

        Returns:
            install.sh content as string
        """
        return """#!/bin/bash
# IteraAgent - ä¾èµ–å®‰è£…è„šæœ¬ (Linux/Mac)

echo "=========================================="
echo "IteraAgent - ä¾èµ–å®‰è£…"
echo "=========================================="
echo ""
echo "ä½¿ç”¨æ¸…åå¤§å­¦é•œåƒæºåŠ é€Ÿä¸‹è½½..."
echo ""

# æ£€æŸ¥ Python ç‰ˆæœ¬
python_version=$(python3 --version 2>&1 | awk '{print $2}')
echo "Python ç‰ˆæœ¬: $python_version"

# ğŸ†• è‡ªåŠ¨åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ (éäº¤äº’æ¨¡å¼)
if [ ! -d "venv" ]; then
    echo "åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ..."
    python3 -m venv venv
    if [ $? -ne 0 ]; then
        echo "âŒ è™šæ‹Ÿç¯å¢ƒåˆ›å»ºå¤±è´¥"
        exit 1
    fi
    echo "âœ… è™šæ‹Ÿç¯å¢ƒå·²åˆ›å»º"
fi

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
echo "æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ..."
source venv/bin/activate
if [ $? -ne 0 ]; then
    echo "âŒ è™šæ‹Ÿç¯å¢ƒæ¿€æ´»å¤±è´¥"
    exit 1
fi

# å®‰è£…ä¾èµ–
echo ""
echo "å¼€å§‹å®‰è£…ä¾èµ–..."
python3 -m pip install -q --upgrade pip -i https://pypi.tuna.tsinghua.edu.cn/simple
python3 -m pip install -q -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple

# æ£€æŸ¥å®‰è£…ç»“æœ
if [ $? -eq 0 ]; then
    echo ""
    echo "=========================================="
    echo "âœ… ä¾èµ–å®‰è£…å®Œæˆ!"
    echo "=========================================="
    echo ""
    echo "ä¸‹ä¸€æ­¥:"
    echo "1. é…ç½® .env æ–‡ä»¶ (å‚è€ƒ .env.template)"
    echo "2. è¿è¡Œ Agent: python agent.py"
    echo "3. è¿è¡Œæµ‹è¯•: pytest tests/test_deepeval.py"
else
    echo ""
    echo "âŒ ä¾èµ–å®‰è£…å¤±è´¥,è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯"
    exit 1
fi
"""

    def _generate_install_script_bat(self) -> str:
        """ğŸ†• Phase 4: ç”Ÿæˆ Windows å®‰è£…è„šæœ¬

        Returns:
            install.bat content as string
        """
        return """@echo off
REM IteraAgent - ä¾èµ–å®‰è£…è„šæœ¬ (Windows)

echo ==========================================
echo IteraAgent - ä¾èµ–å®‰è£…
echo ==========================================
echo.
echo ä½¿ç”¨æ¸…åå¤§å­¦é•œåƒæºåŠ é€Ÿä¸‹è½½...
echo.

REM æ£€æŸ¥ Python ç‰ˆæœ¬
python --version
if errorlevel 1 (
    echo âŒ æœªæ‰¾åˆ° Python,è¯·å…ˆå®‰è£… Python 3.11+
    pause
    exit /b 1
)

REM ğŸ†• è‡ªåŠ¨åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ (éäº¤äº’æ¨¡å¼)
if not exist venv (
    echo åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ...
    python -m venv venv
    if errorlevel 1 (
        echo âŒ è™šæ‹Ÿç¯å¢ƒåˆ›å»ºå¤±è´¥
        pause
        exit /b 1
    )
    echo âœ… è™šæ‹Ÿç¯å¢ƒå·²åˆ›å»º
)

REM æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
echo æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ...
call venv\\Scripts\\activate.bat
if errorlevel 1 (
    echo âŒ è™šæ‹Ÿç¯å¢ƒæ¿€æ´»å¤±è´¥
    pause
    exit /b 1
)

REM å®‰è£…ä¾èµ–
echo.
echo å¼€å§‹å®‰è£…ä¾èµ–...
python -m pip install -q --upgrade pip -i https://pypi.tuna.tsinghua.edu.cn/simple
python -m pip install -q -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple

REM æ£€æŸ¥å®‰è£…ç»“æœ
if errorlevel 1 (
    echo.
    echo âŒ ä¾èµ–å®‰è£…å¤±è´¥,è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯
    pause
    exit /b 1
)

echo.
echo ==========================================
echo âœ… ä¾èµ–å®‰è£…å®Œæˆ!
echo ==========================================
echo.
echo ä¸‹ä¸€æ­¥:
echo 1. é…ç½® .env æ–‡ä»¶ (å‚è€ƒ .env.template)
echo 2. è¿è¡Œ Agent: python agent.py
echo 3. è¿è¡Œæµ‹è¯•: pytest tests\\test_deepeval.py
echo.
pause
"""
