"""Graph Designer - Three-Step Graph Design Module.

This module generates LangGraph structures using a three-step approach:
1. Pattern Selection - Choose design pattern
2. State Definition - Define state schema
3. Nodes & Edges - Design nodes and connections
"""

import yaml
from typing import Optional, List, Dict, Any
from pathlib import Path

from ..schemas import (
    GraphStructure,
    NodeDef,
    EdgeDef,
    ConditionalEdgeDef,
    ProjectMeta,
    ToolsConfig,
    RAGConfig,
    PatternConfig,
    PatternType,
    StateSchema,
    StateField,
    StateFieldType,
    SimulationResult,
    SimulationIssue,
)
from ..llm import BuilderClient


class GraphDesigner:
    """Graph Designer generates LangGraph structures using three-step method.

    The Graph Designer follows a three-step process:
    1. Select Pattern - Choose appropriate design pattern
    2. Define State - Create state schema
    3. Design Graph - Generate nodes and edges
    """

    def __init__(self, builder_client: BuilderClient):
        """Initialize Graph Designer with a builder client.

        Args:
            builder_client: LLM client for graph design
        """
        self.builder = builder_client
        self.pattern_templates = self._load_pattern_templates()

    def _load_pattern_templates(self) -> Dict[PatternType, Dict[str, Any]]:
        """Load pattern templates from YAML files.

        Returns:
            Dict mapping PatternType to template configuration
        """
        templates = {}
        patterns_dir = Path(__file__).parent.parent.parent / "config" / "patterns"

        if not patterns_dir.exists():
            print(f"Warning: Patterns directory not found: {patterns_dir}")
            return templates

        pattern_files = {
            PatternType.SEQUENTIAL: "sequential.yaml",
            PatternType.REFLECTION: "reflection.yaml",
            PatternType.SUPERVISOR: "supervisor.yaml",
            PatternType.PLAN_EXECUTE: "plan_execute.yaml",
        }

        for pattern_type, filename in pattern_files.items():
            file_path = patterns_dir / filename
            if file_path.exists():
                try:
                    with open(file_path, "r", encoding="utf-8") as f:
                        templates[pattern_type] = yaml.safe_load(f)
                except Exception as e:
                    print(f"Warning: Failed to load {filename}: {e}")

        return templates

    # ==================== Step 1: Pattern Selection ====================

    async def select_pattern(self, project_meta: ProjectMeta) -> PatternConfig:
        """Step 1: Select appropriate design pattern.

        Args:
            project_meta: Project metadata

        Returns:
            PatternConfig
        """
        # Use heuristics to select pattern
        pattern_type = self._heuristic_pattern_selection(project_meta)

        # Get template config
        template = self.pattern_templates.get(pattern_type, {})

        # Create PatternConfig
        pattern = PatternConfig(
            pattern_type=pattern_type,
            max_iterations=3,  # Default
            description=template.get("description", ""),
        )

        return pattern

    def _heuristic_pattern_selection(self, project_meta: ProjectMeta) -> PatternType:
        """Heuristic-based pattern selection.

        Args:
            project_meta: Project metadata

        Returns:
            PatternType
        """
        # Check execution plan for complexity
        if project_meta.execution_plan and len(project_meta.execution_plan) > 3:
            # Complex multi-step task -> Plan-Execute
            return PatternType.PLAN_EXECUTE

        # Check for iteration/refinement keywords
        desc_lower = (project_meta.description + project_meta.user_intent_summary).lower()

        if any(
            word in desc_lower
            for word in [
                "è¿­ä»£",
                "æ”¹è¿›",
                "ä¼˜åŒ–",
                "å®¡æ ¸",
                "ä¿®æ”¹",
                "iterate",
                "improve",
                "refine",
                "review",
                "revise",
            ]
        ):
            # Needs iteration -> Reflection
            return PatternType.REFLECTION

        # Check for multiple tools
        if project_meta.complexity_score >= 6:
            # Complex with tools -> Supervisor
            return PatternType.SUPERVISOR

        # Default to Sequential
        return PatternType.SEQUENTIAL

    # ==================== Step 2: State Definition ====================

    async def define_state_schema(
        self, project_meta: ProjectMeta, pattern: PatternConfig
    ) -> StateSchema:
        """Step 2: Define state schema.

        Args:
            project_meta: Project metadata
            pattern: Selected pattern

        Returns:
            StateSchema
        """
        # Start with base fields
        fields = self._get_base_state_fields()

        # Add pattern-specific fields
        pattern_fields = self._get_pattern_state_fields(pattern)
        fields.extend(pattern_fields)

        # Add RAG-specific fields if needed
        if project_meta.has_rag:
            fields.extend(self._get_rag_state_fields())

        return StateSchema(fields=fields)

    def _get_base_state_fields(self) -> List[StateField]:
        """Get base state fields required for all patterns."""
        return [
            StateField(
                name="messages",
                type=StateFieldType.LIST_MESSAGE,
                description="å¯¹è¯å†å²",
                reducer="add_messages",
            ),
            StateField(
                name="is_finished",
                type=StateFieldType.BOOL,
                description="æ˜¯å¦å®Œæˆä»»åŠ¡",
                default=False,
            ),
        ]

    def _get_pattern_state_fields(self, pattern: PatternConfig) -> List[StateField]:
        """Get pattern-specific state fields."""
        fields = []

        if pattern.pattern_type == PatternType.REFLECTION:
            fields.extend(
                [
                    StateField(name="draft", type=StateFieldType.STRING, default=""),
                    StateField(name="feedback", type=StateFieldType.STRING, default=""),
                    StateField(name="iteration_count", type=StateFieldType.INT, default=0),
                    StateField(
                        name="max_iterations",
                        type=StateFieldType.INT,
                        default=pattern.max_iterations,
                    ),
                ]
            )

        elif pattern.pattern_type == PatternType.SUPERVISOR:
            fields.extend(
                [
                    StateField(name="next_action", type=StateFieldType.STRING, default=""),
                    StateField(name="tool_results", type=StateFieldType.DICT, default={}),
                ]
            )

        elif pattern.pattern_type == PatternType.PLAN_EXECUTE:
            fields.extend(
                [
                    StateField(name="plan", type=StateFieldType.LIST_STR, default=[]),
                    StateField(name="current_step", type=StateFieldType.INT, default=0),
                    StateField(name="execution_results", type=StateFieldType.LIST_STR, default=[]),
                    StateField(name="need_replan", type=StateFieldType.BOOL, default=False),
                ]
            )

        return fields

    def _get_rag_state_fields(self) -> List[StateField]:
        """Get RAG-specific state fields."""
        return [
            StateField(
                name="retrieved_docs",
                type=StateFieldType.LIST_STR,
                description="æ£€ç´¢åˆ°çš„æ–‡æ¡£",
                default=[],
            ),
            StateField(
                name="context", type=StateFieldType.STRING, description="RAGä¸Šä¸‹æ–‡", default=""
            ),
            # ğŸ†• v7.2: LLM è¯­ä¹‰è·¯ç”±å­—æ®µ
            StateField(
                name="router_decision",
                type=StateFieldType.OPTIONAL_STR,
                description="è·¯ç”±å†³ç­–ç»“æœ: 'SEARCH' æˆ– 'CHAT'",
                default=None,
            ),
        ]

    # ==================== Step 3: Nodes & Edges Design ====================

    async def design_nodes_and_edges(
        self,
        project_meta: ProjectMeta,
        pattern: PatternConfig,
        state_schema: StateSchema,
        tools_config: Optional[ToolsConfig] = None,
        rag_config: Optional[RAGConfig] = None,
    ) -> GraphStructure:
        """Step 3: Design nodes and edges.

        Args:
            project_meta: Project metadata
            pattern: Selected pattern
            state_schema: State schema
            tools_config: Optional tools configuration
            rag_config: Optional RAG configuration

        Returns:
            GraphStructure
        """
        # Get base structure from pattern template
        template = self.pattern_templates.get(pattern.pattern_type, {})

        nodes = self._create_nodes_from_template(template, pattern)
        edges = self._create_edges_from_template(template)
        conditional_edges = self._create_conditional_edges_from_template(template, pattern)

        # Add RAG node if needed (Router Pattern)
        if project_meta.has_rag and rag_config:
            rag_nodes, rag_edges, rag_cond_edges = self._add_rag_integration(nodes, rag_config)
            nodes.extend(rag_nodes)  # ğŸ†• v7.2: æ·»åŠ  Router å’Œ RAG èŠ‚ç‚¹
            edges.extend(rag_edges)
            conditional_edges.extend(rag_cond_edges)

        # Add tool nodes if needed
        if tools_config and tools_config.enabled_tools:
            tool_nodes, tool_edges = self._add_tool_integration(nodes, tools_config, pattern)
            nodes.extend(tool_nodes)
            edges.extend(tool_edges)

            # Update conditional edges for tools
            if pattern.pattern_type == PatternType.SUPERVISOR:
                conditional_edges = self._update_supervisor_edges(conditional_edges, tools_config)
            # ğŸ”— Fix Sequential Pattern Routing
            elif pattern.pattern_type == PatternType.SEQUENTIAL:
                conditional_edges = self._resolve_tools_placeholder(conditional_edges, tools_config)

            # ğŸ”— Fix Plan-Execute Pattern Routing (Executor -> Tools)
            # We need to ADD a conditional edge from executor -> tools if it doesn't exist?
            # Or assume Executor has it?
            # Plan-Execute template usually doesn't have default cond edge for tools.
            # We must injecting it dynamically here.
            elif pattern.pattern_type == PatternType.PLAN_EXECUTE:
                conditional_edges = self._inject_executor_tool_routing(
                    conditional_edges, tools_config
                )
        else:
            # ğŸ†• No tools - clean up any tool-related conditional edges
            # Remove branches pointing to 'tools' placeholder
            for edge in conditional_edges:
                branches_to_remove = []
                for key, target in edge.branches.items():
                    if target == "tools":
                        branches_to_remove.append(key)

                for key in branches_to_remove:
                    del edge.branches[key]

        # ğŸ†• v7.2: å¦‚æœæœ‰ RAG,Entry Point åº”è¯¥æ˜¯ intent_router
        entry_point = template.get("entry_point", nodes[0].id if nodes else "agent")
        if project_meta.has_rag and rag_config:
            # æ£€æŸ¥æ˜¯å¦æœ‰ intent_router èŠ‚ç‚¹
            if any(n.id == "intent_router" for n in nodes):
                entry_point = "intent_router"

        return GraphStructure(
            pattern=pattern,
            state_schema=state_schema,
            nodes=nodes,
            edges=edges,
            conditional_edges=conditional_edges,
            entry_point=entry_point,
        )

        return nodes

    def _create_nodes_from_template(
        self, template: Dict[str, Any], pattern: PatternConfig
    ) -> List[NodeDef]:
        """Create nodes from pattern template."""
        nodes = []
        default_nodes = template.get("default_nodes", [])
        print(f"ğŸ” [GraphDesigner] Template nodes for {pattern.pattern_type}: {default_nodes}")

        # ğŸ”— Fallback for Sequential Pattern (if template empty)
        if not default_nodes and pattern.pattern_type == PatternType.SEQUENTIAL:
            print("ğŸ”§ [GraphDesigner] Using hardcoded fallback for Sequential Nodes")
            default_nodes = [
                {"id": "agent", "type": "llm", "role_description": "Primary Agent", "config": {}}
            ]

        # ğŸ”— Fallback for Plan-Execute Pattern
        elif not default_nodes and pattern.pattern_type == PatternType.PLAN_EXECUTE:
            print("ğŸ”§ [GraphDesigner] Using hardcoded fallback for Plan-Execute Nodes")
            default_nodes = [
                {"id": "planner", "type": "llm", "role_description": "Planner"},
                {"id": "executor", "type": "llm", "role_description": "Executor"},
                {"id": "replanner", "type": "llm", "role_description": "Replanner"},
            ]

        for node_def in default_nodes:
            nodes.append(
                NodeDef(
                    id=node_def["id"],
                    type=node_def["type"],
                    role_description=node_def.get("role_description"),
                    config=node_def.get("config"),
                )
            )

        return nodes

    def _create_edges_from_template(self, template: Dict[str, Any]) -> List[EdgeDef]:
        """Create edges from pattern template."""
        edges = []
        default_edges = template.get("default_edges", [])

        for edge_def in default_edges:
            edges.append(EdgeDef(source=edge_def["source"], target=edge_def["target"]))

        return edges

    def _create_conditional_edges_from_template(
        self, template: Dict[str, Any], pattern: PatternConfig
    ) -> List[ConditionalEdgeDef]:
        """Create conditional edges from pattern template."""
        conditional_edges = []
        default_cond_edges = template.get("default_conditional_edges", [])

        # ğŸ”— Fallback for Sequential Pattern
        if not default_cond_edges and pattern.pattern_type == PatternType.SEQUENTIAL:
            print("ğŸ”§ [GraphDesigner] Using hardcoded fallback for Sequential Conditional Edges")
            default_cond_edges = [
                {
                    "source": "agent",
                    "condition": "should_continue",
                    # âœ… Fixed: Correct logic to check tool_calls and return tool name
                    "condition_logic": """
last_msg = state.get("messages", [])[-1] if state.get("messages") else None
if last_msg and hasattr(last_msg, "tool_calls") and last_msg.tool_calls:
    return last_msg.tool_calls[0]["name"]
return "end"
""",
                    "branches": {
                        "continue": "tools",  # Placeholder, replaced by _resolve_tools_placeholder
                        "end": "END",
                    },
                }
            ]

        # ğŸ”— Fallback for Plan-Execute Pattern
        elif not default_cond_edges and pattern.pattern_type == PatternType.PLAN_EXECUTE:
            print("ğŸ”§ [GraphDesigner] Using hardcoded fallback for Plan-Execute Conditional Edges")
            default_cond_edges = [
                {
                    "source": "replanner",
                    "condition": "should_end_or_replan",
                    "condition_logic": "return 'end' if state.get('is_finished') else 'continue'",
                    "branches": {"end": "END", "continue": "executor"},
                }
            ]

        for edge_def in default_cond_edges:
            conditional_edges.append(
                ConditionalEdgeDef(
                    source=edge_def["source"],
                    condition=edge_def["condition"],
                    condition_logic=edge_def.get("condition_logic"),
                    branches=edge_def["branches"],
                )
            )

        return conditional_edges

    def _add_rag_integration(
        self, existing_nodes: List[NodeDef], rag_config: RAGConfig
    ) -> tuple[List[NodeDef], List[EdgeDef], List[ConditionalEdgeDef]]:
        """Add RAG node with LLM-based Intent Router Pattern (v7.2).

        New Flow:
        - START -> intent_router (LLMåˆ†ç±»)
        - intent_router -> [SEARCH: rag_retriever | CHAT: agent]
        - rag_retriever -> agent -> END

        Returns:
            Tuple of (new_nodes, edges, conditional_edges)
        """
        # 1. åˆ›å»º Intent Router èŠ‚ç‚¹ (æ–°å¢)
        router_node = NodeDef(
            id="intent_router",
            type="llm",
            role_description="""ä½ æ˜¯ä¸€ä¸ªè·¯ç”±åŠ©æ‰‹ã€‚åˆ†æç”¨æˆ·è¾“å…¥,åˆ¤æ–­æ˜¯å¦éœ€è¦æŸ¥è¯¢çŸ¥è¯†åº“ã€‚

è§„åˆ™:
- å¦‚æœç”¨æˆ·åœ¨è¯¢é—®äº‹å®æ€§é—®é¢˜ã€è¯·æ±‚æ–‡æ¡£ä¿¡æ¯ã€æˆ–éœ€è¦æŸ¥æ‰¾èµ„æ–™,è¾“å‡º 'SEARCH'
- å¦‚æœç”¨æˆ·åªæ˜¯æ‰“æ‹›å‘¼ã€é—²èŠã€æˆ–è¿›è¡Œç®€å•å¯¹è¯,è¾“å‡º 'CHAT'
- åªè¾“å‡º 'SEARCH' æˆ– 'CHAT',ä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹

ç¤ºä¾‹:
- "IteraAgent çš„æ ¸å¿ƒç‰¹æ€§æ˜¯ä»€ä¹ˆ?" -> SEARCH
- "å…·ä½“æ­¥éª¤?" -> SEARCH  
- "ä½ å¥½" -> CHAT
- "è°¢è°¢" -> CHAT""",
            config={"is_router": True},  # æ ‡è®°ä¸ºè·¯ç”±èŠ‚ç‚¹
        )

        # 2. åˆ›å»º RAG æ£€ç´¢èŠ‚ç‚¹
        rag_node = NodeDef(
            id="rag_retriever",
            type="rag",
            role_description="æ£€ç´¢ç›¸å…³æ–‡æ¡£å¹¶è¿”å›ç»™ Agent",
            config={
                "splitter": rag_config.splitter,
                "chunk_size": rag_config.chunk_size,
                "k_retrieval": rag_config.k_retrieval,
            },
        )

        # æ‰¾åˆ°ä¸» Agent èŠ‚ç‚¹
        llm_nodes = [n for n in existing_nodes if n.type == "llm"]
        if not llm_nodes:
            return [router_node, rag_node], [], []

        agent_id = llm_nodes[0].id

        # 3. æ„å»ºè¾¹
        edges = [
            EdgeDef(
                source="rag_retriever", target=agent_id, description="RAG æ£€ç´¢å®Œæˆåè¿”å› Agent"
            ),
            EdgeDef(source=agent_id, target="END", description="Agent å›ç­”åç»“æŸ"),
        ]

        # 4. Router çš„æ¡ä»¶è¾¹ (åŸºäº LLM è¾“å‡º)
        conditional_edges = [
            ConditionalEdgeDef(
                source="intent_router",
                condition="route_by_intent",
                condition_logic="""# LLM è¯­ä¹‰è·¯ç”± (v7.2)
# æ£€æŸ¥ Router èŠ‚ç‚¹çš„è¾“å‡ºå†³ç­–
messages = state.get("messages", [])

if not messages:
    return "chat"

# è·å– Router çš„è¾“å‡º (æœ€åä¸€æ¡ AI æ¶ˆæ¯)
last_message = messages[-1]
decision = ""

if hasattr(last_message, 'content'):
    decision = last_message.content.strip().upper()
elif isinstance(last_message, dict):
    decision = last_message.get("content", "").strip().upper()

# æ ¹æ® Router çš„å†³ç­–è·¯ç”±
if "SEARCH" in decision:
    return "search"
else:
    return "chat"
""",
                branches={"search": "rag_retriever", "chat": agent_id},  # éœ€è¦æ£€ç´¢  # ç›´æ¥å¯¹è¯
            )
        ]

        # è¿”å›æ–°èŠ‚ç‚¹åˆ—è¡¨ã€è¾¹ã€æ¡ä»¶è¾¹
        return [router_node, rag_node], edges, conditional_edges

    def _add_tool_integration(
        self, existing_nodes: List[NodeDef], tools_config: ToolsConfig, pattern: PatternConfig
    ) -> tuple[List[NodeDef], List[EdgeDef]]:
        """Add tool nodes and edges."""
        tool_nodes = []
        tool_edges = []

        for tool_name in tools_config.enabled_tools:
            tool_node = NodeDef(
                id=f"tool_{tool_name}",
                type="tool",
                role_description=f"æ‰§è¡Œ{tool_name}å·¥å…·",
                config={"tool_name": tool_name},
            )
            tool_nodes.append(tool_node)

            # Logic for Return Edges

            # 1. Sequential: Tool -> Agent
            if pattern.pattern_type == PatternType.SEQUENTIAL:
                agent_nodes = [n for n in existing_nodes if n.type == "llm"]
                if agent_nodes:
                    tool_edges.append(EdgeDef(source=f"tool_{tool_name}", target=agent_nodes[0].id))

            # 2. Plan-Execute: Tool -> Executor
            elif pattern.pattern_type == PatternType.PLAN_EXECUTE:
                # Tools used by executor should return execution result to executor
                tool_edges.append(EdgeDef(source=f"tool_{tool_name}", target="executor"))

            # 3. Supervisor: Tool output handled by graph state or specific worker logic
            # (Usually Supervisor pattern uses workers that call tools)

        return tool_nodes, tool_edges

    def _update_supervisor_edges(
        self, conditional_edges: List[ConditionalEdgeDef], tools_config: ToolsConfig
    ) -> List[ConditionalEdgeDef]:
        """Update supervisor conditional edges with tool branches."""
        # Find supervisor routing edge
        for edge in conditional_edges:
            if edge.condition == "route_to_worker":
                # Add tool branches
                for tool_name in tools_config.enabled_tools:
                    edge.branches[tool_name] = f"tool_{tool_name}"

        return conditional_edges

    def _resolve_tools_placeholder(
        self, conditional_edges: List[ConditionalEdgeDef], tools_config: ToolsConfig
    ) -> List[ConditionalEdgeDef]:
        """Resolve 'tools' placeholder in conditional edges for Sequential pattern.

        Replaces:
            branches={"continue": "tools"}
        With:
            branches={
                "tool_a": "tool_tool_a",
                "tool_b": "tool_tool_b"
            }

        And updates condition logic to return tool name.
        """
        for edge in conditional_edges:
            # Check for 'tools' placeholder
            placeholder_key = None
            for key, target in edge.branches.items():
                if target == "tools":
                    placeholder_key = key
                    break

            if placeholder_key:
                # Remove placeholder
                del edge.branches[placeholder_key]

                # Add actual tool nodes
                for tool_name in tools_config.enabled_tools:
                    # branch key = tool_name (what logic returns)
                    # branch target = node_id (where to go)
                    edge.branches[tool_name] = f"tool_{tool_name}"

                # Update condition logic description to reflect this
                # (Actual logic generation happens in Compiler, this is for graph structure validity)
                if not edge.condition_logic or "tools" in edge.condition_logic:
                    # Generic logic description
                    edge.condition_logic = f"""
# Tool Routing Logic
# Returns the name of the tool to call

last_msg = state["messages"][-1]
if hasattr(last_msg, "tool_calls") and last_msg.tool_calls:
    return last_msg.tool_calls[0]["name"]
return "end"
"""
        return conditional_edges

    def _inject_executor_tool_routing(
        self, conditional_edges: List[ConditionalEdgeDef], tools_config: ToolsConfig
    ) -> List[ConditionalEdgeDef]:
        """Inject conditional edge from Executor to Tools for Plan-Execute."""

        # Check if we already have an edge from executor
        has_exec_edge = any(e.source == "executor" for e in conditional_edges)

        if not has_exec_edge:
            branches = {}
            # Add all tools
            for tool_name in tools_config.enabled_tools:
                branches[tool_name] = f"tool_{tool_name}"

            # Add fallback to evaluator (if no tool needed)
            branches["evaluator"] = "evaluator"

            new_edge = ConditionalEdgeDef(
                source="executor",
                condition="execute_step",
                condition_logic="""
# Executor Routing
last_msg = state["messages"][-1]
if hasattr(last_msg, "tool_calls") and last_msg.tool_calls:
    return last_msg.tool_calls[0]["name"]
return "evaluator"
""",
                branches=branches,
            )
            conditional_edges.append(new_edge)
            print(f"ğŸ”§ [GraphDesigner] Injected Executor -> Tools routing edge")

        return conditional_edges

    # ==================== Main Entry Point ====================

    async def design_graph(
        self,
        project_meta: ProjectMeta,
        tools_config: Optional[ToolsConfig] = None,
        rag_config: Optional[RAGConfig] = None,
    ) -> GraphStructure:
        """Design graph structure using three-step method.

        This is the main entry point that orchestrates the three steps.

        Args:
            project_meta: Project metadata
            tools_config: Optional tools configuration
            rag_config: Optional RAG configuration

        Returns:
            GraphStructure
        """
        # Step 1: Select Pattern
        pattern = await self.select_pattern(project_meta)

        # Step 2: Define State
        state_schema = await self.define_state_schema(project_meta, pattern)

        # Step 3: Design Nodes & Edges
        graph = await self.design_nodes_and_edges(
            project_meta, pattern, state_schema, tools_config, rag_config
        )

        # ğŸ†• v8.0: Interface Guard - éªŒè¯å·¥å…·å‚æ•°
        if tools_config and tools_config.enabled_tools:
            await self._validate_tool_parameters(tools_config)

        return graph

    async def _validate_tool_parameters(self, tools_config: ToolsConfig) -> None:
        """éªŒè¯å·¥å…·å‚æ•° Schema (v8.0 Interface Guard)

        Args:
            tools_config: å·¥å…·é…ç½®
        """
        from .interface_guard import InterfaceGuard
        from ..tools import get_global_registry

        print("ğŸ›¡ï¸ [Interface Guard] å¼€å§‹éªŒè¯å·¥å…·å‚æ•°...")

        guard = InterfaceGuard(self.builder, max_retries=3)
        registry = get_global_registry()

        for tool_name in tools_config.enabled_tools:
            metadata = registry.get_metadata(tool_name)

            if not metadata:
                print(f"âš ï¸ [Interface Guard] å·¥å…· {tool_name} æœªåœ¨æ³¨å†Œè¡¨ä¸­æ‰¾åˆ°")
                continue

            if not metadata.openapi_schema:
                print(f"âš ï¸ [Interface Guard] å·¥å…· {tool_name} ç¼ºå°‘ openapi_schema")
                continue

            # ç”Ÿæˆç¤ºä¾‹å‚æ•°è¿›è¡ŒéªŒè¯
            sample_args = self._generate_sample_args(tool_name, metadata)

            # åŒæ­¥éªŒè¯ (ä¸è¿›è¡Œè‡ªåŠ¨ä¿®å¤)
            is_valid, errors = guard.validate_sync(tool_name, sample_args, metadata.openapi_schema)

            if is_valid:
                print(f"âœ… [Interface Guard] å·¥å…· {tool_name} å‚æ•°éªŒè¯é€šè¿‡")
            else:
                print(f"âš ï¸ [Interface Guard] å·¥å…· {tool_name} å‚æ•°éªŒè¯å¤±è´¥:")
                for error in errors:
                    print(f"   - {error.error_message}")

    def _generate_sample_args(self, tool_name: str, metadata) -> Dict[str, Any]:
        """ç”Ÿæˆå·¥å…·çš„ç¤ºä¾‹å‚æ•°ç”¨äºéªŒè¯

        Args:
            tool_name: å·¥å…·åç§°
            metadata: å·¥å…·å…ƒæ•°æ®

        Returns:
            ç¤ºä¾‹å‚æ•°å­—å…¸
        """
        # å¦‚æœæœ‰ç¤ºä¾‹,ä½¿ç”¨ç¬¬ä¸€ä¸ªç¤ºä¾‹
        if metadata.examples and len(metadata.examples) > 0:
            return metadata.examples[0]

        # å¦åˆ™æ ¹æ® Schema ç”Ÿæˆé»˜è®¤å‚æ•°
        schema = metadata.openapi_schema
        sample_args = {}

        properties = schema.get("properties", {})
        required = schema.get("required", [])

        for field_name, field_schema in properties.items():
            field_type = field_schema.get("type", "string")

            # åªä¸ºå¿…å¡«å­—æ®µç”Ÿæˆé»˜è®¤å€¼
            if field_name in required:
                if field_type == "string":
                    sample_args[field_name] = f"sample_{field_name}"
                elif field_type == "integer":
                    sample_args[field_name] = 1
                elif field_type == "number":
                    sample_args[field_name] = 1.0
                elif field_type == "boolean":
                    sample_args[field_name] = True
                elif field_type == "array":
                    sample_args[field_name] = []
                elif field_type == "object":
                    sample_args[field_name] = {}

        return sample_args

    # ==================== Utility Methods ====================

    def save_graph(self, graph: GraphStructure, output_path) -> None:
        """Save graph structure to JSON file."""
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with open(output_path, "w", encoding="utf-8") as f:
            f.write(graph.model_dump_json(indent=2))

    def load_graph(self, input_path) -> GraphStructure:
        """Load graph structure from JSON file."""
        input_path = Path(input_path)

        with open(input_path, "r", encoding="utf-8") as f:
            return GraphStructure.model_validate_json(f.read())

    async def fix_logic(
        self,
        current_graph: GraphStructure,
        simulation_result: Optional[SimulationResult] = None,
        feedback: Optional[str] = None,
    ) -> GraphStructure:
        """æ ¹æ®ä»¿çœŸç»“æœæˆ–åé¦ˆä¿®å¤å›¾ç»“æ„

        Args:
            current_graph: å½“å‰å›¾ç»“æ„
            simulation_result: ä»¿çœŸç»“æœ (å¯é€‰)
            feedback: æ–‡æœ¬åé¦ˆ (å¯é€‰)

        Returns:
            ä¿®å¤åçš„å›¾ç»“æ„
        """
        # æ„å»º Prompt
        issues_desc = ""
        if simulation_result and simulation_result.issues:
            issues_desc += "Simulation Issues:\n"
            for issue in simulation_result.issues:
                issues_desc += f"- [{issue.severity}] {issue.issue_type}: {issue.description}\n"
                if issue.suggestion:
                    issues_desc += f"  Suggestion: {issue.suggestion}\n"

        if feedback:
            issues_desc += f"\nExternal Feedback:\n{feedback}\n"

        if not issues_desc:
            return current_graph

        prompt = f"""# Graph Repair Task

## Current Graph
Pattern: {current_graph.pattern.pattern_type}
Nodes: {', '.join(n.id for n in current_graph.nodes)}

## Issues Detected
{issues_desc}

## Requirement
Please fix the graph structure based on the issues above.
Focus on:
1. Breaking infinite loops (e.g., adding iteration limits)
2. Connecting unreachable nodes
3. Fixing logic errors in conditional edges

## CRITICAL CONSTRAINTS

### 1. Node Targets - Use 'END' for termination
All edge targets MUST be either:
- Actual node IDs from the nodes list above
- The special node "END" (all caps) to terminate the workflow

DO NOT use variants like '__end__', 'end', '__start__', or 'START'.
If you need to end the workflow, use "END" (all caps).

### 2. State Field Types - MUST use exact enum values
type MUST be one of: "str", "int", "bool", "float", "List[BaseMessage]", "List[str]", "Dict[str, Any]", "Optional[str]", "Optional[int]", "Any"
FORBIDDEN: "Optional[List[str]]", "List[Dict]", or custom strings

### 3. Condition Logic - Define all variables first
All variables in condition_logic MUST be defined in state_schema.fields.
Use: state['variable_name'] syntax.

### 4. Prevent Infinite Loops
Add iteration counters with max limits for any loops.

Return the full updated GraphStructure JSON.
"""

        # è°ƒç”¨ LLM ä¿®å¤
        response = await self.builder.call(prompt, schema=GraphStructure)

        # ğŸ”§ åå¤„ç†: ç»Ÿä¸€ç‰¹æ®ŠèŠ‚ç‚¹ä¸º "END"
        if isinstance(response, dict):
            response = self._normalize_special_nodes(response)
            return GraphStructure(**response)
        return response

    def _normalize_special_nodes(self, graph_dict: dict) -> dict:
        """å°†æ‰€æœ‰ç‰¹æ®ŠèŠ‚ç‚¹åç»Ÿä¸€ä¸º 'END'

        LLM å¯èƒ½ç”Ÿæˆ '__end__', 'end', '__END__' ç­‰å˜ä½“,
        ç»Ÿä¸€è½¬æ¢ä¸º LangGraph æ ‡å‡†çš„ 'END'

        Args:
            graph_dict: Graph å­—å…¸

        Returns:
            è§„èŒƒåŒ–åçš„ Graph å­—å…¸
        """
        END_VARIANTS = ["__end__", "end", "__END__", "_end_", "End", "__end", "end__"]

        # å¤„ç† conditional_edges
        for edge in graph_dict.get("conditional_edges", []):
            branches = edge.get("branches", {})
            for key, value in list(branches.items()):
                if value in END_VARIANTS:
                    branches[key] = "END"
                    print(f"ğŸ”§ [GraphDesigner] è§„èŒƒåŒ–èŠ‚ç‚¹: '{value}' â†’ 'END'")

        # å¤„ç† regular edges
        for edge in graph_dict.get("edges", []):
            if edge.get("target") in END_VARIANTS:
                print(f"ğŸ”§ [GraphDesigner] è§„èŒƒåŒ–èŠ‚ç‚¹: '{edge['target']}' â†’ 'END'")
                edge["target"] = "END"

        return graph_dict
